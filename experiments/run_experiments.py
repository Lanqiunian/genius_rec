#!/usr/bin/env python3
"""
GENIUS-Rec å®éªŒç®¡ç†è„šæœ¬
======================

è¿™ä¸ªè„šæœ¬è®¾è®¡äº†å…¨é¢çš„å®éªŒæ¥éªŒè¯GENIUS-Recæ¨¡å‹çš„å„ä¸ªç»„ä»¶å’Œå‡è®¾ï¼š

1. ä¸“å®¶ç³»ç»Ÿå¯¹æ¯”å®éªŒ
2. æ¶æ„é…ç½®å®éªŒ  
3. è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ
4. æ•°æ®å¢å¼ºæ•ˆæœéªŒè¯
5. ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”

ä½¿ç”¨æ–¹æ³•:
    python experiments/run_experiments.py --experiment_suite all
    python experiments/run_experiments.py --experiment_suite expert_ablation
    python experiments/run_experiments.py --experiment_suite hyperparameter_search


    # 1. é¦–æ¬¡è¿è¡Œï¼šå¿«é€ŸéªŒè¯ï¼ˆ30-60åˆ†é’Ÿï¼‰
    python start_experiments.py --mode quick

    # 2. æ·±å…¥ç ”ç©¶ï¼šä¸“å®¶ç³»ç»Ÿåˆ†æï¼ˆ2-4å°æ—¶ï¼‰
    python start_experiments.py --mode expert

    # 3. å®Œæ•´è¯„ä¼°ï¼šæ‰€æœ‰å®éªŒï¼ˆ6-12å°æ—¶ï¼‰  
    python start_experiments.py --mode full

    # 4. ç»“æœåˆ†æ
    python experiments/analyze_results.py
"""

import argparse
import subprocess
import json
import os
import time
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import itertools

class ExperimentRunner:
    def __init__(self, base_dir: str = "/root/autodl-tmp/genius_rec-main"):
        self.base_dir = Path(base_dir)
        self.experiment_dir = self.base_dir / "experiments"
        self.experiment_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå®éªŒæ—¥å¿—
        self.experiment_log = self.experiment_dir / f"experiment_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        self.setup_logging()
        
        # åŸºç¡€è®­ç»ƒå‘½ä»¤
        self.base_cmd = ["python", "-m", "src.train_GeniusRec"]
        self.encoder_weights = "checkpoints/hstu_encoder.pth"
        
        self.results = {}
        
    def setup_logging(self):
        """è®¾ç½®å®éªŒæ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.experiment_log),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def run_single_experiment(self, exp_name: str, args: List[str], save_dir: str = None) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        if save_dir is None:
            save_dir = f"experiments/checkpoints/{exp_name}"
            
        # æ„å»ºå®Œæ•´å‘½ä»¤
        cmd = self.base_cmd + [
            "--encoder_weights_path", self.encoder_weights,
            "--save_dir", save_dir
        ] + args
        
        self.logger.info(f"ğŸš€ å¼€å§‹å®éªŒ: {exp_name}")
        self.logger.info(f"ğŸ“‹ å‘½ä»¤: {' '.join(cmd)}")
        self.logger.info("ğŸ“ˆ è®­ç»ƒè¿›åº¦å°†å®æ—¶æ˜¾ç¤º...")
        
        start_time = time.time()
        captured_output = []
        
        try:
            # ğŸ”§ ä½¿ç”¨Popenå®ç°å®æ—¶è¾“å‡º+æ•è·
            process = subprocess.Popen(
                cmd,
                cwd=self.base_dir,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            # å®æ—¶è¯»å–å¹¶æ˜¾ç¤ºè¾“å‡ºï¼ŒåŒæ—¶ä¿å­˜
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(output.strip())  # å®æ—¶æ˜¾ç¤º
                    captured_output.append(output.strip())  # åŒæ—¶æ•è·
            
            # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            return_code = process.wait(timeout=7200)  # 2å°æ—¶è¶…æ—¶
            duration = time.time() - start_time
            
            # åˆå¹¶æ•è·çš„è¾“å‡º
            full_output = '\n'.join(captured_output)
            
            if return_code == 0:
                self.logger.info(f"âœ… å®éªŒ {exp_name} æˆåŠŸå®Œæˆ (ç”¨æ—¶: {duration:.1f}s)")
                
                # å°è¯•è§£ææœ€ç»ˆç»“æœ
                metrics = self.parse_metrics_from_output(full_output)
                
                return {
                    "status": "success",
                    "duration": duration,
                    "metrics": metrics,
                    "save_dir": save_dir,
                    "args": args
                }
            else:
                self.logger.error(f"âŒ å®éªŒ {exp_name} å¤±è´¥")
                return {
                    "status": "failed",
                    "duration": duration,
                    "return_code": return_code,
                    "args": args
                }
                
        except subprocess.TimeoutExpired:
            self.logger.error(f"â° å®éªŒ {exp_name} è¶…æ—¶")
            process.kill()
            return {
                "status": "timeout",
                "duration": 7200,
                "args": args
            }
        except Exception as e:
            self.logger.error(f"ğŸ’¥ å®éªŒ {exp_name} å¼‚å¸¸: {e}")
            return {
                "status": "error",
                "error": str(e),
                "args": args
            }
    
    def parse_metrics_from_output(self, output: str) -> Dict[str, float]:
        """ä»è®­ç»ƒè¾“å‡ºä¸­è§£ææœ€ç»ˆæŒ‡æ ‡"""
        metrics = {}
        lines = output.split('\n')
        
        for line in lines:
            # è§£ææµ‹è¯•ç»“æœ - é€‚é…å½“å‰è¾“å‡ºæ ¼å¼
            if "Test HR@10:" in line:
                try:
                    hr_value = float(line.split(":")[1].strip())
                    metrics["test_hr"] = hr_value
                except:
                    pass
                    
            if "Test NDCG@10:" in line:
                try:
                    ndcg_value = float(line.split(":")[1].strip())
                    metrics["test_ndcg"] = ndcg_value
                except:
                    pass
                    
            # è§£æéªŒè¯ç»“æœ
            if "Best validation loss:" in line:
                try:
                    val_loss = float(line.split(":")[1].strip())
                    metrics["best_val_loss"] = val_loss
                except:
                    pass
                    
            # è§£æè®­ç»ƒå®Œæˆæ ‡å¿—
            if "training finished" in line.lower():
                metrics["training_completed"] = True
        
        return metrics

    def expert_ablation_experiments(self):
        """ä¸“å®¶ç³»ç»Ÿæ¶ˆèå®éªŒ"""
        self.logger.info("ğŸ§  å¼€å§‹ä¸“å®¶ç³»ç»Ÿæ¶ˆèå®éªŒ")
        
        expert_configs = [
            # å•ä¸“å®¶å®éªŒ
            ("behavior_only", ["--disable_content_expert", "--disable_image_expert"]),
            ("content_only", ["--disable_behavior_expert", "--disable_image_expert"]), 
            ("image_only", ["--disable_behavior_expert", "--disable_content_expert", "--enable_image_expert"]),
            
            # åŒä¸“å®¶å®éªŒ
            ("behavior_content", ["--disable_image_expert"]),  # è¡Œä¸º+å†…å®¹ä¸“å®¶
            ("behavior_image", ["--disable_content_expert", "--enable_image_expert"]),
            ("content_image", ["--disable_behavior_expert", "--enable_image_expert"]),
            
            # å…¨ä¸“å®¶å®éªŒ
            ("all_experts", ["--enable_image_expert"]),
            
            # ä¼ ç»ŸåŸºçº¿ï¼ˆä»…è¡Œä¸ºä¸“å®¶ï¼‰
            ("baseline_traditional", ["--disable_content_expert", "--disable_image_expert"]),
        ]
        
        results = {}
        for exp_name, args in expert_configs:
            full_exp_name = f"expert_ablation_{exp_name}"
            result = self.run_single_experiment(
                full_exp_name, 
                args,
                f"experiments/checkpoints/expert_ablation/{exp_name}"
            )
            results[full_exp_name] = result
            
        self.results.update(results)
        return results
    
    def architecture_experiments(self):
        """æ¶æ„é…ç½®å®éªŒ"""
        self.logger.info("ğŸ—ï¸ å¼€å§‹æ¶æ„é…ç½®å®éªŒ")
        
        # è¿™äº›éœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶æˆ–åˆ›å»ºä¸´æ—¶é…ç½®
        arch_configs = [
            # ç¼–ç å™¨å†»ç»“ vs å¾®è°ƒ
            ("finetuned_encoder", []),  # é»˜è®¤å¾®è°ƒç¼–ç å™¨
            ("frozen_encoder", ["--freeze_encoder"]),  # å†»ç»“ç¼–ç å™¨
            
            # ä¸åŒçš„è§£ç å™¨å±‚æ•°ï¼ˆéœ€è¦é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ä¿®æ”¹ï¼‰
            ("deep_decoder", []),  # å¯ä»¥é€šè¿‡é…ç½®è°ƒæ•´
            ("shallow_decoder", []),
        ]
        
        results = {}
        for exp_name, args in arch_configs:
            full_exp_name = f"architecture_{exp_name}"
            result = self.run_single_experiment(
                full_exp_name,
                args,
                f"experiments/checkpoints/architecture/{exp_name}"
            )
            results[full_exp_name] = result
            
        self.results.update(results)
        return results
    
    def hyperparameter_search(self):
        """è¶…å‚æ•°æœç´¢å®éªŒ"""
        self.logger.info("ğŸ›ï¸ å¼€å§‹è¶…å‚æ•°æœç´¢å®éªŒ")
        
        # ç”±äºè¶…å‚æ•°åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼Œè¿™é‡Œä¸»è¦æµ‹è¯•å¯é€šè¿‡å‘½ä»¤è¡Œæ§åˆ¶çš„å‚æ•°
        # å¯ä»¥åˆ›å»ºä¸åŒçš„é…ç½®æ–‡ä»¶æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡
        
        hyperparameter_configs = [
            # ä¸åŒçš„ä¿å­˜ç›®å½•ä»¥é¿å…å†²çª
            ("baseline_hp", []),
            
            # è¿™é‡Œå¯ä»¥æ‰©å±•æ›´å¤šè¶…å‚æ•°
            # æ¯”å¦‚é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®å­¦ä¹ ç‡ã€batch sizeç­‰
        ]
        
        results = {}
        for exp_name, args in hyperparameter_configs:
            full_exp_name = f"hyperparameter_{exp_name}"
            result = self.run_single_experiment(
                full_exp_name,
                args,
                f"experiments/checkpoints/hyperparameter/{exp_name}"
            )
            results[full_exp_name] = result
            
        self.results.update(results)
        return results
    
    def data_augmentation_experiments(self):
        """æ•°æ®å¢å¼ºæ•ˆæœå®éªŒ"""
        self.logger.info("ğŸ“š å¼€å§‹æ•°æ®å¢å¼ºæ•ˆæœå®éªŒ")
        
        # æµ‹è¯•å›¾åƒåµŒå…¥çš„æ•ˆæœ - ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
        data_configs = [
            ("no_image_embeddings", ["--disable_image_expert"]),  # ç¦ç”¨å›¾åƒä¸“å®¶
            ("with_image_embeddings", ["--enable_image_expert"]),  # å¯ç”¨å›¾åƒä¸“å®¶ï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤è·¯å¾„
        ]
        
        results = {}
        for exp_name, args in data_configs:
            full_exp_name = f"data_augmentation_{exp_name}"
            result = self.run_single_experiment(
                full_exp_name,
                args,
                f"experiments/checkpoints/data_augmentation/{exp_name}"
            )
            results[full_exp_name] = result
            
        self.results.update(results)
        return results
    
    def baseline_comparison_experiments(self):
        """ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”å®éªŒ"""
        self.logger.info("ğŸ“Š å¼€å§‹åŸºçº¿å¯¹æ¯”å®éªŒ")
        
        # è¿è¡Œä¼ ç»ŸåŸºçº¿æ¨¡å‹
        baseline_cmd = ["python", "-m", "baseline.train_baseline"]
        
        self.logger.info("ğŸ”„ è¿è¡Œä¼ ç»ŸTransformeråŸºçº¿...")
        
        try:
            result = subprocess.run(
                baseline_cmd,
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=3600  # 1å°æ—¶è¶…æ—¶
            )
            
            if result.returncode == 0:
                baseline_metrics = self.parse_metrics_from_output(result.stdout)
                self.results["baseline_transformer"] = {
                    "status": "success",
                    "metrics": baseline_metrics,
                    "type": "baseline"
                }
                self.logger.info("âœ… åŸºçº¿å®éªŒå®Œæˆ")
            else:
                self.logger.error("âŒ åŸºçº¿å®éªŒå¤±è´¥")
                self.results["baseline_transformer"] = {
                    "status": "failed",
                    "error": result.stderr,
                    "type": "baseline"
                }
                
        except subprocess.TimeoutExpired:
            self.logger.error("â° åŸºçº¿å®éªŒè¶…æ—¶")
            self.results["baseline_transformer"] = {
                "status": "timeout",
                "type": "baseline"
            }
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        results_file = self.experiment_dir / f"experiment_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
            
        self.logger.info(f"ğŸ“„ å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        # ç”Ÿæˆç®€åŒ–çš„ç»“æœæŠ¥å‘Š
        self.generate_summary_report()
    
    def generate_summary_report(self):
        """ç”Ÿæˆå®éªŒç»“æœæ‘˜è¦æŠ¥å‘Š"""
        report_file = self.experiment_dir / f"experiment_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# GENIUS-Rec å®éªŒç»“æœæŠ¥å‘Š\n\n")
            f.write(f"å®éªŒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # ä¸“å®¶ç³»ç»Ÿæ¶ˆèå®éªŒç»“æœ
            f.write("## ğŸ§  ä¸“å®¶ç³»ç»Ÿæ¶ˆèå®éªŒ\n\n")
            f.write("| å®éªŒé…ç½® | çŠ¶æ€ | Test HR@10 | Test NDCG@10 | æœ€ä½³éªŒè¯æŸå¤± |\n")
            f.write("|---------|------|------------|--------------|-------------|\n")
            
            for exp_name, result in self.results.items():
                if exp_name.startswith("expert_ablation"):
                    status = result.get("status", "unknown")
                    metrics = result.get("metrics", {})
                    hr = metrics.get("test_hr", "N/A")
                    ndcg = metrics.get("test_ndcg", "N/A") 
                    val_loss = metrics.get("best_val_loss", "N/A")
                    
                    config_name = exp_name.replace("expert_ablation_", "")
                    f.write(f"| {config_name} | {status} | {hr} | {ndcg} | {val_loss} |\n")
            
            f.write("\n## ğŸ—ï¸ æ¶æ„é…ç½®å®éªŒ\n\n")
            f.write("| æ¶æ„é…ç½® | çŠ¶æ€ | Test HR@10 | Test NDCG@10 | æœ€ä½³éªŒè¯æŸå¤± |\n")
            f.write("|---------|------|------------|--------------|-------------|\n")
            
            for exp_name, result in self.results.items():
                if exp_name.startswith("architecture"):
                    status = result.get("status", "unknown")
                    metrics = result.get("metrics", {})
                    hr = metrics.get("test_hr", "N/A")
                    ndcg = metrics.get("test_ndcg", "N/A")
                    val_loss = metrics.get("best_val_loss", "N/A")
                    
                    config_name = exp_name.replace("architecture_", "")
                    f.write(f"| {config_name} | {status} | {hr} | {ndcg} | {val_loss} |\n")
            
            f.write("\n## ğŸ“ˆ å…³é”®å‘ç°\n\n")
            f.write("### æœ€ä½³é…ç½®\n")
            
            # æ‰¾åˆ°æœ€ä½³HR@10ç»“æœ
            best_hr = 0
            best_hr_config = None
            
            for exp_name, result in self.results.items():
                if result.get("status") == "success":
                    metrics = result.get("metrics", {})
                    hr = metrics.get("test_hr", 0)
                    if hr > best_hr:
                        best_hr = hr
                        best_hr_config = exp_name
            
            if best_hr_config:
                f.write(f"- **æœ€ä½³HR@10**: {best_hr:.4f} (é…ç½®: {best_hr_config})\n")
            
            f.write("\n### ä¸“å®¶ç³»ç»Ÿæ•ˆæœåˆ†æ\n")
            f.write("- [ ] åˆ†æä¸åŒä¸“å®¶ç»„åˆçš„æ€§èƒ½å·®å¼‚\n")
            f.write("- [ ] éªŒè¯å¤šæ¨¡æ€ä¿¡æ¯çš„ä»·å€¼\n")
            f.write("- [ ] è¯„ä¼°è®¡ç®—å¤æ‚åº¦ vs æ€§èƒ½æå‡çš„æƒè¡¡\n")
            
        self.logger.info(f"ğŸ“‹ å®éªŒæ‘˜è¦æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

    def quick_validation_experiments(self):
        """å¿«é€ŸéªŒè¯å®éªŒï¼ˆç”¨äºè°ƒè¯•å’Œå¿«é€Ÿè¿­ä»£ï¼‰"""
        self.logger.info("âš¡ å¼€å§‹å¿«é€ŸéªŒè¯å®éªŒ")
        
        quick_configs = [
            ("quick_behavior_only", ["--disable_content_expert"]),
            ("quick_all_experts", ["--enable_image_expert"]),
        ]
        
        results = {}
        for exp_name, args in quick_configs:
            # å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®æ›´å°‘çš„epochsç”¨äºå¿«é€ŸéªŒè¯
            result = self.run_single_experiment(
                exp_name,
                args,
                f"experiments/checkpoints/quick_validation/{exp_name}"
            )
            results[exp_name] = result
            
        self.results.update(results)
        return results

def main():
    parser = argparse.ArgumentParser(description="GENIUS-Rec å®éªŒç®¡ç†è„šæœ¬")
    parser.add_argument(
        "--experiment_suite", 
        choices=["all", "expert_ablation", "architecture", "hyperparameter", "data_augmentation", "baseline_comparison", "quick_validation"],
        default="expert_ablation",
        help="é€‰æ‹©è¦è¿è¡Œçš„å®éªŒå¥—ä»¶"
    )
    parser.add_argument("--base_dir", type=str, default="/root/autodl-tmp/genius_rec-main", help="é¡¹ç›®æ ¹ç›®å½•")
    
    args = parser.parse_args()
    
    runner = ExperimentRunner(args.base_dir)
    
    runner.logger.info("ğŸ¯ GENIUS-Rec å®éªŒå¼€å§‹")
    runner.logger.info(f"ğŸ“‚ é¡¹ç›®ç›®å½•: {args.base_dir}")
    runner.logger.info(f"ğŸ§ª å®éªŒå¥—ä»¶: {args.experiment_suite}")
    
    if args.experiment_suite == "all":
        runner.expert_ablation_experiments()
        runner.architecture_experiments()
        runner.hyperparameter_search()
        runner.data_augmentation_experiments()
        runner.baseline_comparison_experiments()
    elif args.experiment_suite == "expert_ablation":
        runner.expert_ablation_experiments()
    elif args.experiment_suite == "architecture":
        runner.architecture_experiments()
    elif args.experiment_suite == "hyperparameter":
        runner.hyperparameter_search()
    elif args.experiment_suite == "data_augmentation":
        runner.data_augmentation_experiments()
    elif args.experiment_suite == "baseline_comparison":
        runner.baseline_comparison_experiments()
    elif args.experiment_suite == "quick_validation":
        runner.quick_validation_experiments()
    
    runner.save_results()
    runner.logger.info("ğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")

if __name__ == "__main__":
    main()
