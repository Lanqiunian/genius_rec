#!/usr/bin/env python3
"""
GENIUS-Rec è§£ç å™¨æ¶æ„æµ‹è¯•
=======================

ä¸“é—¨æµ‹è¯•å½“å‰å¤šä¸“å®¶è§£ç å™¨æ¶æ„çš„å„é¡¹åŠŸèƒ½
"""

import sys
import torch
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°path
sys.path.append(str(Path(__file__).parent.parent))

from src.config import get_config
from src.decoder.decoder import GenerativeDecoder

def test_decoder_initialization():
    """æµ‹è¯•è§£ç å™¨åˆå§‹åŒ–"""
    print("ğŸ”§ æµ‹è¯•è§£ç å™¨åˆå§‹åŒ–...")
    
    config = get_config()
    expert_config = config.get('expert_system', {})
    
    try:
        decoder = GenerativeDecoder(
            num_items=10000,
            embedding_dim=64,
            num_layers=4,
            num_heads=4,
            ffn_hidden_dim=256,
            max_seq_len=50,
            expert_config=expert_config
        )
        
        print("âœ… è§£ç å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"ğŸ“‹ å¯ç”¨çš„ä¸“å®¶: {decoder.enabled_experts}")
        
        # æ£€æŸ¥å„ä¸“å®¶ç»„ä»¶
        if hasattr(decoder, 'behavior_expert_fc'):
            print("âœ… è¡Œä¸ºä¸“å®¶ç»„ä»¶å­˜åœ¨")
        if hasattr(decoder, 'content_expert_attention'):
            print("âœ… å†…å®¹ä¸“å®¶æ³¨æ„åŠ›ç»„ä»¶å­˜åœ¨")
        if hasattr(decoder, 'image_expert_attention'):
            print("âœ… å›¾åƒä¸“å®¶æ³¨æ„åŠ›ç»„ä»¶å­˜åœ¨")
        if hasattr(decoder, 'gate_network'):
            print("âœ… é—¨æ§ç½‘ç»œç»„ä»¶å­˜åœ¨")
            
        return decoder
        
    except Exception as e:
        print(f"âŒ è§£ç å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def test_decoder_forward_pass(decoder):
    """æµ‹è¯•è§£ç å™¨å‰å‘ä¼ æ’­"""
    print("\nğŸ”„ æµ‹è¯•è§£ç å™¨å‰å‘ä¼ æ’­...")
    
    try:
        batch_size, seq_len = 4, 20
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        target_ids = torch.randint(0, 1000, (batch_size, seq_len))
        encoder_output = torch.randn(batch_size, seq_len, 64)
        memory_padding_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)
        
        print(f"ğŸ“Š è¾“å…¥å½¢çŠ¶:")
        print(f"  - target_ids: {target_ids.shape}")
        print(f"  - encoder_output: {encoder_output.shape}")
        print(f"  - memory_padding_mask: {memory_padding_mask.shape}")
        
        # æµ‹è¯•æ­£å¸¸å‰å‘ä¼ æ’­
        with torch.no_grad():
            logits, weights, balancing_loss = decoder(
                target_ids, encoder_output, memory_padding_mask,
                return_weights=True, force_equal_weights=False
            )
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"ğŸ“Š è¾“å‡ºå½¢çŠ¶:")
        print(f"  - logits: {logits.shape}")
        print(f"  - weights: {weights.shape if weights is not None else 'None'}")
        print(f"  - balancing_loss: {balancing_loss.item():.6f}")
        
        # æµ‹è¯•ç­‰æƒé‡æ¨¡å¼
        with torch.no_grad():
            logits_eq, weights_eq, balancing_loss_eq = decoder(
                target_ids, encoder_output, memory_padding_mask,
                return_weights=True, force_equal_weights=True
            )
        
        print(f"âœ… ç­‰æƒé‡æ¨¡å¼æˆåŠŸ")
        print(f"ğŸ“Š ç­‰æƒé‡è¾“å‡º:")
        print(f"  - logits: {logits_eq.shape}")
        print(f"  - balancing_loss: {balancing_loss_eq.item():.6f}")
        
        # æ£€æŸ¥æƒé‡åˆ†å¸ƒ
        if weights is not None:
            print(f"ğŸ“Š ä¸“å®¶æƒé‡ç»Ÿè®¡:")
            for i in range(weights.shape[-1]):
                expert_weights = weights[:, :, i]
                print(f"  - ä¸“å®¶{i}: å‡å€¼={expert_weights.mean().item():.4f}, æ ‡å‡†å·®={expert_weights.std().item():.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_expert_configurations():
    """æµ‹è¯•ä¸åŒä¸“å®¶é…ç½®"""
    print("\nâš™ï¸ æµ‹è¯•ä¸åŒä¸“å®¶é…ç½®...")
    
    base_config = get_config()
    
    test_configs = [
        {
            "name": "ä»…è¡Œä¸ºä¸“å®¶",
            "experts": {
                "behavior_expert": True,
                "content_expert": False,
                "image_expert": False
            }
        },
        {
            "name": "è¡Œä¸º+å†…å®¹ä¸“å®¶",
            "experts": {
                "behavior_expert": True,
                "content_expert": True,
                "image_expert": False
            }
        },
        {
            "name": "å…¨ä¸“å®¶é…ç½®",
            "experts": {
                "behavior_expert": True,
                "content_expert": True,
                "image_expert": True
            }
        }
    ]
    
    for test_config in test_configs:
        print(f"\nğŸ“‹ æµ‹è¯•é…ç½®: {test_config['name']}")
        
        # ä¿®æ”¹ä¸“å®¶é…ç½®
        expert_config = base_config['expert_system'].copy()
        expert_config['experts'] = test_config['experts']
        
        try:
            decoder = GenerativeDecoder(
                num_items=1000,
                embedding_dim=64,
                num_layers=2,  # ä½¿ç”¨è¾ƒå°çš„é…ç½®ä»¥åŠ å¿«æµ‹è¯•
                num_heads=4,
                ffn_hidden_dim=128,
                max_seq_len=20,
                expert_config=expert_config
            )
            
            print(f"âœ… {test_config['name']} åˆå§‹åŒ–æˆåŠŸ")
            print(f"   å¯ç”¨ä¸“å®¶: {decoder.enabled_experts}")
            
            # å¿«é€Ÿå‰å‘ä¼ æ’­æµ‹è¯•
            batch_size, seq_len = 2, 10
            target_ids = torch.randint(0, 1000, (batch_size, seq_len))
            encoder_output = torch.randn(batch_size, seq_len, 64)
            memory_padding_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)
            
            with torch.no_grad():
                logits, weights, balancing_loss = decoder(
                    target_ids, encoder_output, memory_padding_mask,
                    return_weights=True, force_equal_weights=False
                )
            
            print(f"   å‰å‘ä¼ æ’­æˆåŠŸ: logits {logits.shape}")
            
        except Exception as e:
            print(f"âŒ {test_config['name']} å¤±è´¥: {e}")

def test_embedding_loading():
    """æµ‹è¯•åµŒå…¥åŠ è½½åŠŸèƒ½"""
    print("\nğŸ“¥ æµ‹è¯•åµŒå…¥åŠ è½½åŠŸèƒ½...")
    
    config = get_config()
    expert_config = config.get('expert_system', {})
    
    try:
        decoder = GenerativeDecoder(
            num_items=1000,
            embedding_dim=64,
            num_layers=2,
            num_heads=4,
            ffn_hidden_dim=128,
            max_seq_len=20,
            expert_config=expert_config
        )
        
        # æµ‹è¯•æ–‡æœ¬åµŒå…¥åŠ è½½
        if expert_config['experts'].get('content_expert', False):
            print("ğŸ“„ æµ‹è¯•æ–‡æœ¬åµŒå…¥åŠ è½½...")
            text_embedding_dim = expert_config['content_expert']['text_embedding_dim']
            fake_text_embeddings = torch.randn(1000, text_embedding_dim)
            decoder.load_text_embeddings(fake_text_embeddings, verbose=True)
        
        # æµ‹è¯•å›¾åƒåµŒå…¥åŠ è½½
        if expert_config['experts'].get('image_expert', False):
            print("ğŸ–¼ï¸ æµ‹è¯•å›¾åƒåµŒå…¥åŠ è½½...")
            image_embedding_dim = expert_config['image_expert']['image_embedding_dim']
            fake_image_embeddings = torch.randn(1000, image_embedding_dim)
            decoder.load_image_embeddings(fake_image_embeddings, verbose=True)
        
        print("âœ… åµŒå…¥åŠ è½½æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ åµŒå…¥åŠ è½½æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ GENIUS-Rec è§£ç å™¨æ¶æ„æµ‹è¯•")
    print("="*50)
    
    # 1. åˆå§‹åŒ–æµ‹è¯•
    decoder = test_decoder_initialization()
    if decoder is None:
        print("âŒ åˆå§‹åŒ–å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
        return
    
    # 2. å‰å‘ä¼ æ’­æµ‹è¯•
    if not test_decoder_forward_pass(decoder):
        print("âŒ å‰å‘ä¼ æ’­å¤±è´¥")
        return
    
    # 3. ä¸åŒé…ç½®æµ‹è¯•
    test_expert_configurations()
    
    # 4. åµŒå…¥åŠ è½½æµ‹è¯•
    test_embedding_loading()
    
    print("\n" + "="*50)
    print("ğŸ‰ è§£ç å™¨æ¶æ„æµ‹è¯•å®Œæˆï¼")
    print("âœ… å½“å‰è§£ç å™¨æ¶æ„çŠ¶æ€è‰¯å¥½ï¼Œå¯ä»¥è¿›è¡Œå®éªŒ")

if __name__ == "__main__":
    main()
