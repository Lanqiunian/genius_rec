#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹å‚æ•°é‡è®¡ç®—è„šæœ¬
ç”¨äºåˆ†æGeniusRecæ¨¡å‹çš„æ€»å‚æ•°æ•°é‡
"""

import torch
import pickle
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append('/root/autodl-tmp/genius_rec-main')

from src.config import get_config
from src.GeniusRec import GENIUSRecModel

def count_parameters(model):
    """è®¡ç®—æ¨¡å‹çš„æ€»å‚æ•°æ•°é‡"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    return total_params, trainable_params

def format_number(num):
    """æ ¼å¼åŒ–æ•°å­—ï¼Œä»¥Bã€Mã€Kä¸ºå•ä½"""
    if num >= 1e9:
        return f"{num/1e9:.2f}B"
    elif num >= 1e6:
        return f"{num/1e6:.2f}M"
    elif num >= 1e3:
        return f"{num/1e3:.2f}K"
    else:
        return str(num)

def analyze_model_components(model):
    """åˆ†ææ¨¡å‹å„ç»„ä»¶çš„å‚æ•°é‡"""
    print("\n=== æ¨¡å‹ç»„ä»¶å‚æ•°è¯¦ç»†åˆ†æ ===")
    
    # åˆ†æç¼–ç å™¨
    encoder_params = sum(p.numel() for p in model.encoder.parameters())
    print(f"ğŸ§  ç¼–ç å™¨(HSTU)æ€»å‚æ•°: {format_number(encoder_params)}")
    
    # ç¼–ç å™¨å†…éƒ¨ç»„ä»¶
    if hasattr(model.encoder, 'item_embedding'):
        item_emb_params = model.encoder.item_embedding.weight.numel()
        print(f"  â””â”€ ç‰©å“åµŒå…¥å±‚: {format_number(item_emb_params)}")
    
    if hasattr(model.encoder, 'encoder_layers'):
        layer_params = sum(p.numel() for p in model.encoder.encoder_layers.parameters())
        num_layers = len(model.encoder.encoder_layers)
        print(f"  â””â”€ HSTUå±‚ ({num_layers}å±‚): {format_number(layer_params)}")
        print(f"      â””â”€ å¹³å‡æ¯å±‚: {format_number(layer_params // num_layers)}")
    
    # åˆ†æè§£ç å™¨
    decoder_params = sum(p.numel() for p in model.decoder.parameters())
    print(f"\nğŸ¯ è§£ç å™¨(GenerativeDecoder)æ€»å‚æ•°: {format_number(decoder_params)}")
    
    # è§£ç å™¨å†…éƒ¨ç»„ä»¶
    if hasattr(model.decoder, 'item_embedding'):
        decoder_item_emb_params = model.decoder.item_embedding.weight.numel()
        print(f"  â””â”€ ç‰©å“åµŒå…¥å±‚: {format_number(decoder_item_emb_params)}")
    
    if hasattr(model.decoder, 'pos_embedding'):
        pos_emb_params = model.decoder.pos_embedding.weight.numel()
        print(f"  â””â”€ ä½ç½®åµŒå…¥å±‚: {format_number(pos_emb_params)}")
    
    if hasattr(model.decoder, 'decoder_layers'):
        decoder_layer_params = sum(p.numel() for p in model.decoder.decoder_layers.parameters())
        num_decoder_layers = len(model.decoder.decoder_layers)
        print(f"  â””â”€ è§£ç å™¨å±‚ ({num_decoder_layers}å±‚): {format_number(decoder_layer_params)}")
        print(f"      â””â”€ å¹³å‡æ¯å±‚: {format_number(decoder_layer_params // num_decoder_layers)}")
    
    # åˆ†æä¸“å®¶ç³»ç»Ÿ
    expert_params = 0
    print(f"\nğŸ”§ ä¸“å®¶ç³»ç»Ÿå‚æ•°:")
    
    # è¡Œä¸ºä¸“å®¶
    if hasattr(model.decoder, 'behavior_expert_fc'):
        behavior_params = sum(p.numel() for p in model.decoder.behavior_expert_fc.parameters())
        expert_params += behavior_params
        print(f"  â””â”€ è¡Œä¸ºä¸“å®¶: {format_number(behavior_params)}")
    
    # å†…å®¹ä¸“å®¶
    if hasattr(model.decoder, 'text_embedding'):
        text_emb_params = model.decoder.text_embedding.weight.numel()
        expert_params += text_emb_params
        print(f"  â””â”€ æ–‡æœ¬åµŒå…¥: {format_number(text_emb_params)}")
    
    if hasattr(model.decoder, 'content_expert_attention'):
        content_attn_params = sum(p.numel() for p in model.decoder.content_expert_attention.parameters())
        expert_params += content_attn_params
        print(f"  â””â”€ å†…å®¹æ³¨æ„åŠ›: {format_number(content_attn_params)}")
    
    if hasattr(model.decoder, 'content_attention_projection'):
        content_proj_params = sum(p.numel() for p in model.decoder.content_attention_projection.parameters())
        expert_params += content_proj_params
        print(f"  â””â”€ å†…å®¹æŠ•å½±: {format_number(content_proj_params)}")
    
    # å›¾åƒä¸“å®¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if hasattr(model.decoder, 'image_embedding'):
        image_emb_params = model.decoder.image_embedding.weight.numel()
        expert_params += image_emb_params
        print(f"  â””â”€ å›¾åƒåµŒå…¥: {format_number(image_emb_params)}")
    
    # é—¨æ§ç½‘ç»œ
    if hasattr(model.decoder, 'gate_network'):
        gate_params = sum(p.numel() for p in model.decoder.gate_network.parameters())
        expert_params += gate_params
        print(f"  â””â”€ é—¨æ§ç½‘ç»œ: {format_number(gate_params)}")
    
    print(f"  ğŸ”§ ä¸“å®¶ç³»ç»Ÿæ€»è®¡: {format_number(expert_params)}")
    
    return encoder_params, decoder_params, expert_params

def main():
    print("ğŸš€ å¼€å§‹è®¡ç®—GeniusRecæ¨¡å‹å‚æ•°é‡...")
    
    # åŠ è½½é…ç½®
    config = get_config()
    
    # åŠ è½½IDæ˜ å°„ä»¥è·å–ç‰©å“æ•°é‡
    id_maps_path = config["data"]["id_maps_file"]
    
    if not os.path.exists(id_maps_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°IDæ˜ å°„æ–‡ä»¶ '{id_maps_path}'")
        print("è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬ç”Ÿæˆè¯¥æ–‡ä»¶")
        return
    
    print(f"ğŸ“‚ åŠ è½½IDæ˜ å°„æ–‡ä»¶: {id_maps_path}")
    with open(id_maps_path, 'rb') as f:
        id_maps = pickle.load(f)
    
    num_items = len(id_maps['item_map'])
    num_users = len(id_maps['user_map'])
    
    print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  â””â”€ ç‰©å“æ•°é‡: {num_items:,}")
    print(f"  â””â”€ ç”¨æˆ·æ•°é‡: {num_users:,}")
    
    # æ„å»ºæ¨¡å‹é…ç½®
    encoder_config = config["encoder_model"].copy()
    encoder_config['item_num'] = num_items
    encoder_config['pad_token_id'] = config["pad_token_id"]
    
    decoder_config = config["decoder_model"].copy()
    decoder_config['num_items'] = num_items
    decoder_config['pad_token_id'] = config["pad_token_id"]
    
    expert_config = config["expert_system"]
    
    print(f"\nğŸ”§ æ¨¡å‹é…ç½®:")
    print(f"  ç¼–ç å™¨é…ç½®: {encoder_config}")
    print(f"  è§£ç å™¨é…ç½®: {decoder_config}")
    print(f"  ä¸“å®¶ç³»ç»Ÿé…ç½®: {expert_config}")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  æ­£åœ¨æ„å»ºæ¨¡å‹...")
    model = GENIUSRecModel(
        encoder_config=encoder_config,
        decoder_config=decoder_config,
        expert_config=expert_config
    )
    
    # è®¡ç®—å‚æ•°é‡
    total_params, trainable_params = count_parameters(model)
    
    print(f"\n" + "="*60)
    print(f"ğŸ“ˆ GeniusRecæ¨¡å‹å‚æ•°é‡ç»Ÿè®¡")
    print(f"="*60)
    print(f"ğŸ”¢ æ€»å‚æ•°æ•°é‡: {total_params:,} ({format_number(total_params)})")
    print(f"ğŸ¯ å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({format_number(trainable_params)})")
    print(f"ğŸ”’ å†»ç»“å‚æ•°: {total_params - trainable_params:,} ({format_number(total_params - trainable_params)})")
    
    # è¯¦ç»†ç»„ä»¶åˆ†æ
    encoder_params, decoder_params, expert_params = analyze_model_components(model)
    
    print(f"\n" + "="*60)
    print(f"ğŸ“Š å‚æ•°åˆ†å¸ƒæ¦‚è§ˆ")
    print(f"="*60)
    print(f"ç¼–ç å™¨: {format_number(encoder_params)} ({encoder_params/total_params*100:.1f}%)")
    print(f"è§£ç å™¨: {format_number(decoder_params)} ({decoder_params/total_params*100:.1f}%)")
    print(f"  â””â”€ å…¶ä¸­ä¸“å®¶ç³»ç»Ÿ: {format_number(expert_params)} ({expert_params/total_params*100:.1f}%)")
    
    # æ¨¡å‹å¤§å°ä¼°ç®—ï¼ˆFP32ï¼‰
    model_size_mb = total_params * 4 / (1024 * 1024)  # 4 bytes per parameter
    print(f"\nğŸ’¾ æ¨¡å‹å¤§å°ä¼°ç®—:")
    print(f"  â””â”€ FP32: {model_size_mb:.1f} MB")
    print(f"  â””â”€ FP16: {model_size_mb/2:.1f} MB")
    
    # æ€»ç»“
    if total_params >= 1e9:
        scale = "Bçº§"
        color = "ğŸ”¥"
    elif total_params >= 1e8:
        scale = "ç™¾Mçº§"
        color = "ğŸš€"
    elif total_params >= 1e7:
        scale = "åMçº§"
        color = "ğŸ’ª"
    else:
        scale = "Mçº§ä»¥ä¸‹"
        color = "âœ¨"
    
    print(f"\n{color} æ€»ç»“: æ‚¨çš„GeniusRecæ¨¡å‹æ˜¯ä¸€ä¸ª {scale} æ¨¡å‹ ({format_number(total_params)})")
    
    return total_params, trainable_params

if __name__ == "__main__":
    main()
