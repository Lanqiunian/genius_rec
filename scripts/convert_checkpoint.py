#!/usr/bin/env python3
"""
Windows to Linux Checkpoint Converter for PyTorch Models

This script converts PyTorch checkpoint files from Windows format to Linux-compatible format,
fixing path separator issues and ensuring proper serialization compatibility.

Usage:
    python convert_checkpoint.py --input checkpoints/hstu_encoder.pth --output checkpoints/hstu_encoder_linux.pth
    python convert_checkpoint.py --input checkpoints/hstu_encoder.pth --backup --overwrite
"""

import argparse
import logging
import os
import shutil
from pathlib import Path, PosixPath, WindowsPath
import torch
import platform
import pickle
import io

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

class PathPickleCompatibility:
    """å¤„ç†Windowså’ŒLinuxä¹‹é—´çš„è·¯å¾„å…¼å®¹æ€§é—®é¢˜"""
    
    @staticmethod
    def path_constructor(loader, node):
        """è‡ªå®šä¹‰è·¯å¾„æ„é€ å™¨ï¼Œå°†WindowsPathè½¬æ¢ä¸ºPosixPath"""
        path_str = loader.construct_scalar(node)
        # å°†Windowsè·¯å¾„åˆ†éš”ç¬¦è½¬æ¢ä¸ºUnixæ ¼å¼
        unix_path = path_str.replace('\\', '/')
        return PosixPath(unix_path)
    
    @staticmethod
    def setup_pickle_compatibility():
        """è®¾ç½®pickleå…¼å®¹æ€§ä»¥å¤„ç†è·¨å¹³å°è·¯å¾„é—®é¢˜"""
        # æ³¨å†Œè·¯å¾„ç±»å‹çš„å…¼å®¹æ€§å¤„ç†
        def windows_path_constructor(self, *args, **kwargs):
            # å°†WindowsPathè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œç„¶ååˆ›å»ºPosixPath
            if args:
                path_str = str(args[0]).replace('\\', '/')
                return PosixPath(path_str)
            return PosixPath()
        
        # ä¸´æ—¶æ›¿æ¢WindowsPathç±»
        original_windows_path = None
        try:
            import pathlib
            original_windows_path = pathlib.WindowsPath
            pathlib.WindowsPath = lambda *args, **kwargs: PosixPath(str(args[0]).replace('\\', '/') if args else "")
        except:
            pass
        
        return original_windows_path

class CustomUnpickler(pickle.Unpickler):
    """è‡ªå®šä¹‰unpickleræ¥å¤„ç†è·¨å¹³å°å…¼å®¹æ€§é—®é¢˜"""
    
    def find_class(self, module, name):
        # å¤„ç†WindowsPathç±»
        if module == 'pathlib' and name == 'WindowsPath':
            return PosixPath
        elif module == 'pathlib' and name == 'PosixPath':
            return PosixPath
        # å…¶ä»–è·¯å¾„ç›¸å…³çš„ç±»ä¹Ÿè¿›è¡Œè½¬æ¢
        elif 'Path' in name and 'pathlib' in module:
            return PosixPath
        
        return super().find_class(module, name)

def backup_checkpoint(file_path):
    """åˆ›å»ºåŸæ–‡ä»¶çš„å¤‡ä»½"""
    backup_path = str(file_path) + '.backup'
    shutil.copy2(file_path, backup_path)
    logging.info(f"âœ… åŸæ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_path}")
    return backup_path

def fix_state_dict_keys(state_dict):
    """
    ä¿®å¤state_dictä¸­å¯èƒ½å­˜åœ¨çš„è·¯å¾„ç›¸å…³é—®é¢˜
    """
    if isinstance(state_dict, dict):
        fixed_dict = {}
        for key, value in state_dict.items():
            # åªå¯¹å­—ç¬¦ä¸²ç±»å‹çš„é”®è¿›è¡Œè·¯å¾„åˆ†éš”ç¬¦æ›¿æ¢
            if isinstance(key, str):
                fixed_key = key.replace('\\', '/')
            else:
                fixed_key = key
            
            if isinstance(value, dict):
                fixed_dict[fixed_key] = fix_state_dict_keys(value)
            else:
                fixed_dict[fixed_key] = value
        return fixed_dict
    return state_dict

def convert_paths_in_object(obj):
    """
    é€’å½’è½¬æ¢å¯¹è±¡ä¸­çš„æ‰€æœ‰è·¯å¾„å¯¹è±¡ä¸ºLinuxå…¼å®¹æ ¼å¼
    """
    try:
        if isinstance(obj, (WindowsPath, PosixPath)):
            # å°†ä»»ä½•è·¯å¾„å¯¹è±¡è½¬æ¢ä¸ºPosixPath
            path_str = str(obj).replace('\\', '/')
            return PosixPath(path_str)
        elif isinstance(obj, dict):
            converted_dict = {}
            for key, value in obj.items():
                # åªå¯¹å­—ç¬¦ä¸²ç±»å‹çš„é”®è¿›è¡Œå¤„ç†
                if isinstance(key, str):
                    converted_key = key.replace('\\', '/')
                else:
                    converted_key = key
                converted_dict[converted_key] = convert_paths_in_object(value)
            return converted_dict
        elif isinstance(obj, (list, tuple)):
            converted = [convert_paths_in_object(item) for item in obj]
            return type(obj)(converted)
        elif isinstance(obj, str):
            # ä¿®å¤å­—ç¬¦ä¸²ä¸­å¯èƒ½çš„Windowsè·¯å¾„åˆ†éš”ç¬¦ï¼Œä½†åªå¤„ç†çœ‹èµ·æ¥åƒè·¯å¾„çš„å­—ç¬¦ä¸²
            if '\\' in obj and ('/' in obj or ':' in obj or len(obj.split('\\')) > 1):
                return obj.replace('\\', '/')
            return obj
        else:
            return obj
    except Exception as e:
        # å¦‚æœè½¬æ¢è¿‡ç¨‹ä¸­å‡ºç°ä»»ä½•é—®é¢˜ï¼Œè¿”å›åŸå¯¹è±¡
        logging.warning(f"è½¬æ¢å¯¹è±¡æ—¶å‡ºç°é”™è¯¯: {e}, è¿”å›åŸå¯¹è±¡")
        return obj

def convert_checkpoint(input_path, output_path=None, overwrite=False, create_backup=True):
    """
    è½¬æ¢checkpointæ–‡ä»¶ä»Windowsæ ¼å¼åˆ°Linuxå…¼å®¹æ ¼å¼
    
    Args:
        input_path (str): è¾“å…¥checkpointæ–‡ä»¶è·¯å¾„
        output_path (str, optional): è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è¦†ç›–åŸæ–‡ä»¶
        overwrite (bool): æ˜¯å¦è¦†ç›–åŸæ–‡ä»¶
        create_backup (bool): æ˜¯å¦åˆ›å»ºå¤‡ä»½
    """
    input_path = Path(input_path)
    
    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_path is None:
        if overwrite:
            output_path = input_path
        else:
            output_path = input_path.parent / f"{input_path.stem}_linux{input_path.suffix}"
    else:
        output_path = Path(output_path)
    
    # åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœéœ€è¦ä¸”è¦è¦†ç›–åŸæ–‡ä»¶ï¼‰
    backup_path = None
    if create_backup and (overwrite or output_path == input_path):
        backup_path = backup_checkpoint(input_path)
    
    try:
        logging.info(f"ğŸ”„ å¼€å§‹è½¬æ¢checkpoint: {input_path}")
        
        # å°è¯•åŠ è½½checkpointï¼Œä½¿ç”¨ä¸åŒçš„å…¼å®¹æ€§è®¾ç½®
        checkpoint_loaded = False
        checkpoint = None
        
        # æ–¹æ³•1: ä½¿ç”¨è‡ªå®šä¹‰unpicklerå¤„ç†è·¯å¾„å…¼å®¹æ€§
        try:
            logging.info("ğŸ”§ å°è¯•ä½¿ç”¨è‡ªå®šä¹‰unpicklerè§£å†³è·¯å¾„å…¼å®¹æ€§é—®é¢˜...")
            with open(input_path, 'rb') as f:
                unpickler = CustomUnpickler(f)
                checkpoint = unpickler.load()
            checkpoint_loaded = True
            logging.info("âœ… ä½¿ç”¨è‡ªå®šä¹‰unpickleræˆåŠŸåŠ è½½checkpoint")
        except Exception as e:
            logging.warning(f"è‡ªå®šä¹‰unpickleræ–¹æ³•å¤±è´¥: {e}")
        
        # æ–¹æ³•2: è®¾ç½®è·¯å¾„å…¼å®¹æ€§åæ ‡å‡†åŠ è½½
        if not checkpoint_loaded:
            try:
                logging.info("ğŸ”§ å°è¯•è®¾ç½®è·¯å¾„å…¼å®¹æ€§ååŠ è½½...")
                path_compat = PathPickleCompatibility()
                original_path = path_compat.setup_pickle_compatibility()
                
                checkpoint = torch.load(input_path, map_location='cpu', weights_only=False)
                checkpoint_loaded = True
                logging.info("âœ… ä½¿ç”¨è·¯å¾„å…¼å®¹æ€§æ–¹æ³•æˆåŠŸåŠ è½½checkpoint")
                
            except Exception as e:
                logging.warning(f"è·¯å¾„å…¼å®¹æ€§æ–¹æ³•å¤±è´¥: {e}")
        
        # æ–¹æ³•3: ä½¿ç”¨pickleæ¨¡å—ç›´æ¥å¤„ç†
        if not checkpoint_loaded:
            try:
                logging.info("ğŸ”§ å°è¯•ä½¿ç”¨pickleæ¨¡å—ç›´æ¥å¤„ç†...")
                with open(input_path, 'rb') as f:
                    # è®¾ç½®pickleçš„find_globalæ¥å¤„ç†è·¯å¾„ç±»
                    def safe_find_global(module, name):
                        if module == 'pathlib':
                            if name in ['WindowsPath', 'PosixPath']:
                                return PosixPath
                        return getattr(__import__(module, fromlist=['']), name)
                    
                    original_find_global = pickle.Unpickler.find_class
                    pickle.Unpickler.find_class = lambda self, module, name: safe_find_global(module, name)
                    
                    try:
                        checkpoint = pickle.load(f)
                        checkpoint_loaded = True
                        logging.info("âœ… ä½¿ç”¨pickleç›´æ¥å¤„ç†æˆåŠŸåŠ è½½checkpoint")
                    finally:
                        pickle.Unpickler.find_class = original_find_global
                        
            except Exception as e:
                logging.warning(f"pickleç›´æ¥å¤„ç†æ–¹æ³•å¤±è´¥: {e}")
        
        # æ–¹æ³•4: æœ€åå°è¯•å¼ºåˆ¶è½¬æ¢
        if not checkpoint_loaded:
            try:
                logging.info("ğŸ”§ å°è¯•å¼ºåˆ¶è½¬æ¢æ–¹æ³•...")
                # ä¸´æ—¶monkey patch pathlib
                import pathlib
                original_windows_path = getattr(pathlib, 'WindowsPath', None)
                
                # åˆ›å»ºä¸€ä¸ªå…¼å®¹çš„WindowsPathç±»
                class CompatWindowsPath:
                    def __new__(cls, *args, **kwargs):
                        if args:
                            path_str = str(args[0]).replace('\\', '/')
                            return PosixPath(path_str)
                        return PosixPath()
                
                pathlib.WindowsPath = CompatWindowsPath
                
                try:
                    checkpoint = torch.load(input_path, map_location='cpu', weights_only=False)
                    checkpoint_loaded = True
                    logging.info("âœ… ä½¿ç”¨å¼ºåˆ¶è½¬æ¢æ–¹æ³•æˆåŠŸåŠ è½½checkpoint")
                finally:
                    if original_windows_path:
                        pathlib.WindowsPath = original_windows_path
                        
            except Exception as e:
                logging.warning(f"å¼ºåˆ¶è½¬æ¢æ–¹æ³•å¤±è´¥: {e}")
        
        if not checkpoint_loaded:
            raise RuntimeError(f"æ‰€æœ‰åŠ è½½æ–¹æ³•éƒ½å¤±è´¥äº†ã€‚è¿™ä¸ªcheckpointå¯èƒ½ä¸¥é‡æŸåæˆ–ä½¿ç”¨äº†ä¸å…¼å®¹çš„æ ¼å¼ã€‚")
        
        # æ£€æŸ¥checkpointæ ¼å¼å¹¶è¿›è¡Œè½¬æ¢
        if isinstance(checkpoint, dict):
            # ä¿®å¤å¯èƒ½çš„è·¯å¾„é—®é¢˜
            checkpoint = fix_state_dict_keys(checkpoint)
            
            # é€’å½’å¤„ç†æ‰€æœ‰å¯èƒ½çš„è·¯å¾„å¯¹è±¡
            checkpoint = convert_paths_in_object(checkpoint)
            
            # æŠ¥å‘Šcheckpointå†…å®¹
            if 'model_state_dict' in checkpoint:
                logging.info("ğŸ” æ£€æµ‹åˆ°å®Œæ•´checkpointæ ¼å¼ (åŒ…å«model_state_dict)")
                if 'epoch' in checkpoint:
                    logging.info(f"   - Epoch: {checkpoint['epoch']}")
                if 'optimizer_state_dict' in checkpoint:
                    logging.info("   - åŒ…å«optimizerçŠ¶æ€")
                if 'scheduler_state_dict' in checkpoint:
                    logging.info("   - åŒ…å«schedulerçŠ¶æ€")
                    
                # æ£€æŸ¥æ¨¡å‹å‚æ•°æ•°é‡
                model_params = checkpoint['model_state_dict']
                param_count = len(model_params)
                logging.info(f"   - æ¨¡å‹å‚æ•°æ•°é‡: {param_count}")
                
            else:
                logging.info("ğŸ” æ£€æµ‹åˆ°çº¯æƒé‡æ ¼å¼")
                param_count = len(checkpoint)
                logging.info(f"   - å‚æ•°æ•°é‡: {param_count}")
        else:
            logging.warning("âš ï¸ æœªçŸ¥çš„checkpointæ ¼å¼")
            # ä»ç„¶å°è¯•è½¬æ¢å¯èƒ½çš„è·¯å¾„å¯¹è±¡
            checkpoint = convert_paths_in_object(checkpoint)
        
        # ä¿å­˜è½¬æ¢åçš„checkpoint
        logging.info(f"ğŸ’¾ ä¿å­˜è½¬æ¢åçš„checkpointåˆ°: {output_path}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨Linuxå…¼å®¹çš„ä¿å­˜æ–¹å¼
        torch.save(checkpoint, output_path, pickle_protocol=4)
        
        logging.info("âœ… Checkpointè½¬æ¢å®Œæˆ!")
        
        # éªŒè¯è½¬æ¢åçš„æ–‡ä»¶
        logging.info("ğŸ” éªŒè¯è½¬æ¢åçš„æ–‡ä»¶...")
        try:
            verification_checkpoint = torch.load(output_path, map_location='cpu', weights_only=False)
            logging.info("âœ… è½¬æ¢åçš„æ–‡ä»¶éªŒè¯æˆåŠŸ!")
            
            # æ¯”è¾ƒæ–‡ä»¶å¤§å°
            original_size = input_path.stat().st_size / (1024 * 1024)  # MB
            converted_size = output_path.stat().st_size / (1024 * 1024)  # MB
            
            logging.info(f"ğŸ“Š æ–‡ä»¶å¤§å°å¯¹æ¯”:")
            logging.info(f"   - åŸæ–‡ä»¶: {original_size:.2f} MB")
            logging.info(f"   - è½¬æ¢å: {converted_size:.2f} MB")
            
            size_diff_percent = abs(converted_size - original_size) / original_size * 100
            if size_diff_percent < 5:  # 5%ä»¥å†…çš„å·®å¼‚æ˜¯æ­£å¸¸çš„
                logging.info(f"   - å¤§å°å·®å¼‚: {size_diff_percent:.2f}% (æ­£å¸¸)")
            else:
                logging.warning(f"   - å¤§å°å·®å¼‚: {size_diff_percent:.2f}% (å¯èƒ½æœ‰é—®é¢˜)")
            
        except Exception as e:
            logging.error(f"âŒ è½¬æ¢åæ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            if backup_path and output_path == input_path:
                logging.info(f"ğŸ”„ æ¢å¤å¤‡ä»½æ–‡ä»¶...")
                shutil.copy2(backup_path, input_path)
            raise
        
        return str(output_path)
        
    except Exception as e:
        logging.error(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        if backup_path and output_path == input_path:
            logging.info(f"ğŸ”„ æ¢å¤å¤‡ä»½æ–‡ä»¶...")
            shutil.copy2(backup_path, input_path)
        raise

def main():
    setup_logging()
    
    parser = argparse.ArgumentParser(description="Convert PyTorch checkpoint from Windows to Linux format")
    parser.add_argument('--input', '-i', required=True, help='Input checkpoint file path')
    parser.add_argument('--output', '-o', help='Output checkpoint file path (optional)')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite the original file')
    parser.add_argument('--backup', action='store_true', default=True, help='Create backup of original file (default: True)')
    parser.add_argument('--no-backup', action='store_true', help='Do not create backup')
    
    args = parser.parse_args()
    
    # å¤„ç†å¤‡ä»½é€‰é¡¹
    create_backup = args.backup and not args.no_backup
    
    logging.info("=== PyTorch Checkpointè½¬æ¢å·¥å…· ===")
    logging.info(f"ğŸ–¥ï¸  å½“å‰ç³»ç»Ÿ: {platform.system()} {platform.release()}")
    logging.info(f"ğŸ Pythonç‰ˆæœ¬: {platform.python_version()}")
    logging.info(f"ğŸ”¥ PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    try:
        output_file = convert_checkpoint(
            args.input, 
            args.output, 
            args.overwrite, 
            create_backup
        )
        
        logging.info("=" * 50)
        logging.info("ğŸ‰ è½¬æ¢æˆåŠŸå®Œæˆ!")
        logging.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        logging.info("ğŸ’¡ ç°åœ¨å¯ä»¥åœ¨Linuxç¯å¢ƒä¸‹æ­£å¸¸ä½¿ç”¨è¯¥checkpointäº†")
        
        # æä¾›ä½¿ç”¨å»ºè®®
        if 'hstu_encoder' in args.input:
            logging.info("\nğŸ“‹ ä½¿ç”¨å»ºè®®:")
            logging.info("   # ç«¯åˆ°ç«¯å¾®è°ƒï¼ˆæ¨èï¼‰:")
            logging.info("   python -m src.train_GeniusRec --encoder_weights_path checkpoints/hstu_encoder.pth")
            logging.info("   # å†»ç»“ç¼–ç å™¨ï¼ˆå¯¹æ¯”å®éªŒï¼‰:")
            logging.info("   python -m src.train_GeniusRec --encoder_weights_path checkpoints/hstu_encoder.pth --freeze_encoder")
        
    except Exception as e:
        logging.error(f"ğŸ’¥ è½¬æ¢å¤±è´¥: {e}")
        return 1
    
    return 0

if __name__ == '__main__':
    exit(main())
