# evaluate_checkpoint.py (æœ€ç»ˆä¿®å¤ç‰ˆ)

import argparse
import logging
import os
import pickle
import numpy as np
from collections import OrderedDict

import torch
import torch.nn as nn
from torch.utils.data import DataLoader

# --- å¯¼å…¥æ‚¨é¡¹ç›®ä¸­çš„å¿…è¦ç»„ä»¶ ---
from src.config import get_config
from src.GeniusRec import GENIUSRecModel
from src.dataset import Seq2SeqRecDataset
from src.unified_evaluation import evaluate_model_validation_with_ranking

def fix_state_dict_keys(state_dict):
    """
    æ™ºèƒ½ä¿®å¤state_dictä¸­çš„é”®åï¼Œä»¥é€‚é…æ¨¡å‹æ¶æ„çš„å˜æ›´ã€‚
    å°†æ—§çš„ content_expert_attention æƒé‡é‡å‘½åä¸ºæ–°çš„ shared_cross_attentionã€‚
    """
    new_state_dict = OrderedDict()
    for old_key, value in state_dict.items():
        new_key = old_key
        # å¦‚æœé”®ååŒ…å«æ—§çš„æ³¨æ„åŠ›æ¨¡å—åç§°ï¼Œå°†å…¶æ›¿æ¢ä¸ºæ–°çš„å…±äº«æ¨¡å—åç§°
        if "content_expert_attention" in old_key:
            new_key = old_key.replace("content_expert_attention", "shared_cross_attention")
            logging.info(f"é”®åè½¬æ¢: '{old_key}' -> '{new_key}'")
        # å¿½ç•¥æ‰å·²ç»è¢«åºŸå¼ƒçš„ image_expert_attention çš„æƒé‡
        elif "image_expert_attention" in old_key:
            logging.warning(f"å‘ç°å·²åºŸå¼ƒçš„é”®: '{old_key}'ï¼Œå°†äºˆä»¥å¿½ç•¥ã€‚")
            continue
            
        new_state_dict[new_key] = value
        
    return new_state_dict


def run_evaluation():
    """
    ä¸€ä¸ªå¥å£®çš„ä¸´æ—¶è„šæœ¬ï¼Œç”¨äºåŠ è½½æ£€æŸ¥ç‚¹å¹¶ä½¿ç”¨ä¿®æ­£åçš„é€»è¾‘è¿›è¡Œä¸€æ¬¡æ€§è¯„ä¼°ã€‚
    """
    # 1. è®¾ç½®: å‚æ•°ã€é…ç½®ã€è®¾å¤‡ã€æ—¥å¿—
    # =================================================================
    parser = argparse.ArgumentParser(description="Evaluate a GENIUS-Rec Checkpoint")
    parser.add_argument('--checkpoint_path', type=str, required=True, help='Path to the model checkpoint file (.pth).')
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    config = get_config()
    device = torch.device(config['device'])
    logging.info(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # 2. åŠ è½½æ•°æ®å’Œå…ƒæ•°æ®
    # =================================================================
    logging.info("æ­£åœ¨åŠ è½½æ•°æ®å’ŒIDæ˜ å°„...")
    try:
        with open(config['data']['id_maps_file'], 'rb') as f:
            id_maps = pickle.load(f)
        val_dataset = Seq2SeqRecDataset(config, config['data']['validation_file'])
    except FileNotFoundError as e:
        logging.error(f"æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {e}ã€‚è¯·å…ˆè¿è¡Œ preprocess.pyã€‚")
        return

    num_special_tokens = id_maps.get('num_special_tokens', 4)
    total_vocab_size = id_maps['num_items'] + num_special_tokens
    config['encoder_model']['item_num'] = total_vocab_size
    config['decoder_model']['num_items'] = total_vocab_size
    pad_token_id = config['pad_token_id']
    top_k = config['evaluation']['top_k']

    val_loader = DataLoader(
        val_dataset,
        batch_size=config['finetune']['batch_size'] * 4,
        shuffle=False,
        num_workers=config['finetune'].get('num_workers', 0)
    )
    logging.info(f"å·²åŠ è½½ {len(val_dataset)} ä¸ªéªŒè¯æ ·æœ¬ã€‚")

    # 3. åˆå§‹åŒ–æ¨¡å‹
    # =================================================================
    logging.info("æ­£åœ¨åˆå§‹åŒ– GENIUS-Rec æ¨¡å‹...")
    model = GENIUSRecModel(config['encoder_model'], config['decoder_model'], config['expert_system']).to(device)

    # 4. ã€æ ¸å¿ƒä¿®å¤ã€‘åœ¨åŠ è½½æ£€æŸ¥ç‚¹ *ä¹‹å‰*ï¼Œå®Œæˆæ‰€æœ‰å‡†å¤‡å·¥ä½œ
    # =================================================================
    
    # æ­¥éª¤ A: åŠ è½½å¤–éƒ¨åµŒå…¥ä»¥ç¡®ä¿å°ºå¯¸æ­£ç¡®
    logging.info("æ­£åœ¨åŠ è½½å¤–éƒ¨åµŒå…¥çŸ©é˜µä»¥åŒæ­¥æ¨¡å‹å°ºå¯¸...")
    # åŠ è½½æ–‡æœ¬åµŒå…¥
    text_embedding_file = config['data']['data_dir'] / 'book_gemini_embeddings_filtered_migrated.npy'
    text_embeddings_dict = np.load(text_embedding_file, allow_pickle=True).item()
    text_embedding_dim = next(iter(text_embeddings_dict.values())).shape[0]
    text_embedding_matrix = torch.zeros(total_vocab_size, text_embedding_dim, dtype=torch.float)
    item_asin_map = id_maps['item_map']
    for asin, embedding in text_embeddings_dict.items():
        if asin in item_asin_map:
            text_embedding_matrix[item_asin_map[asin]] = torch.tensor(embedding, dtype=torch.float)
    model.decoder.load_text_embeddings(text_embedding_matrix.to(device), verbose=False)
    
    # åŠ è½½å›¾åƒåµŒå…¥
    image_embeddings_path = "data/book_image_embeddings_migrated.npy"
    image_embeddings_dict = np.load(image_embeddings_path, allow_pickle=True).item()
    image_embedding_dim = next(iter(image_embeddings_dict.values())).shape[0]
    image_embedding_matrix = torch.randn(total_vocab_size, image_embedding_dim, dtype=torch.float) * 0.01
    for item_id, embedding in image_embeddings_dict.items():
        if isinstance(item_id, (int, np.int32, np.int64)) and 0 <= item_id < total_vocab_size:
            image_embedding_matrix[item_id] = torch.tensor(embedding, dtype=torch.float)
    model.decoder.load_image_embeddings(image_embedding_matrix.to(device), verbose=False)
    logging.info("âœ… å¤–éƒ¨åµŒå…¥åŠ è½½å®Œæˆï¼Œæ¨¡å‹å°ºå¯¸å·²åŒæ­¥ã€‚")

    # æ­¥éª¤ B: åº”ç”¨æƒé‡ç»‘å®š
    if model.decoder.final_projection is not None:
        model.decoder.final_projection.weight = model.encoder.item_embedding.weight
        logging.info("âœ… æƒé‡ç»‘å®šå·²åº”ç”¨ã€‚")

    # 5. åŠ è½½æ£€æŸ¥ç‚¹ (åŒ…å«æ™ºèƒ½ä¿®å¤é€»è¾‘)
    # =================================================================
    if not os.path.exists(args.checkpoint_path):
        logging.error(f"æ£€æŸ¥ç‚¹æ–‡ä»¶æœªæ‰¾åˆ°: {args.checkpoint_path}")
        return
        
    logging.info(f"æ­£åœ¨ä» '{args.checkpoint_path}' åŠ è½½æ¨¡å‹çŠ¶æ€...")
    checkpoint = torch.load(args.checkpoint_path, map_location=device)
    
    # æ­¥éª¤ C: æ™ºèƒ½ä¿®å¤é”®å
    fixed_state_dict = fix_state_dict_keys(checkpoint['model_state_dict'])
    
    # ä½¿ç”¨ä¿®å¤åçš„ state_dict åŠ è½½ï¼Œè®¾ç½® strict=False ä»¥å¿½ç•¥ä¸åŒ¹é…çš„é”®
    model.load_state_dict(fixed_state_dict, strict=False)
    logging.info("âœ… æ¨¡å‹çŠ¶æ€åŠ è½½æˆåŠŸ (å·²æ™ºèƒ½ä¿®å¤æ¶æ„ä¸åŒ¹é…é—®é¢˜)ã€‚")

    # 6. è¿è¡Œè¯„ä¼°
    # =================================================================
    logging.info("æ­£åœ¨ä½¿ç”¨ä¿®æ­£åçš„é€»è¾‘å¼€å§‹è¯„ä¼°...")
    criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)
    
    eval_results = evaluate_model_validation_with_ranking(
        model=model, val_loader=val_loader, criterion=criterion, device=device,
        epoch=0, num_epochs=1, pad_token_id=pad_token_id, config=config, top_k=top_k
    )

    # 7. æ‰“å°ç»“æœ
    # =================================================================
    logging.info("ğŸ‰ --- è¯„ä¼°å®Œæˆ --- ğŸ‰")
    logging.info(f"  ğŸ“ˆ éªŒè¯é›† Loss: {eval_results['val_loss']:.4f}")
    logging.info(f"  ğŸ“Š éªŒè¯é›† PPL: {eval_results['val_ppl']:.4f}")
    logging.info(f"  ğŸ¯ éªŒè¯é›† HR@{top_k}: {eval_results['val_hr']:.4f}")
    logging.info(f"  ğŸ¯ éªŒè¯é›† NDCG@{top_k}: {eval_results['val_ndcg']:.4f}")
    
    enabled_experts = [k for k, v in config['expert_system']['experts'].items() if v]
    for expert_name in enabled_experts:
        weight_key = f'avg_{expert_name}_weight'
        if weight_key in eval_results:
            logging.info(f"  âš–ï¸  {expert_name.replace('_', ' ').title()} æƒé‡: {eval_results[weight_key]:.4f}")

if __name__ == '__main__':
    run_evaluation()