#!/usr/bin/env python
"""
å¿«é€ŸéªŒè¯è„šæœ¬ - éªŒè¯é—¨æ§ç½‘ç»œç»´åº¦ä¿®å¤æ˜¯å¦æœ‰æ•ˆ

è¯¥è„šæœ¬ä¼š:
1. åŠ è½½æ¨¡å‹å’Œé…ç½®
2. åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆæ•…æ„ä½¿ç”¨ä¸åŒçš„åºåˆ—é•¿åº¦ï¼‰
3. æ‰§è¡Œæ¨¡å‹å‰å‘ä¼ æ’­
4. æ¨¡æ‹Ÿè¯„ä¼°æµç¨‹ä¸­çš„æƒé‡å¤„ç†é€»è¾‘
5. å¦‚æœæ‰€æœ‰æ­¥éª¤éƒ½æ²¡æœ‰é”™è¯¯ï¼Œåˆ™ä¿®å¤å·²ç”Ÿæ•ˆ

ä½¿ç”¨æ–¹æ³•:
python scripts/validate_fixes.py
"""

import os
import sys
import torch
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
project_dir = os.path.dirname(script_dir)
sys.path.insert(0, project_dir)

from src.config import get_config
from src.GeniusRec import GENIUSRecModel
import torch.nn.functional as F

def create_test_data(batch_size=2, source_len=64, target_len=20, embedding_dim=64):
    """åˆ›å»ºæµ‹è¯•æ•°æ®ï¼Œæ¨¡æ‹Ÿä¸åŒçš„åºåˆ—é•¿åº¦"""
    source_ids = torch.randint(1, 1000, (batch_size, source_len))
    target_ids = torch.randint(1, 1000, (batch_size, target_len))
    
    # åˆ›å»ºå¡«å……æ©ç  (éšæœºåˆ¶é€ ä¸€äº›å¡«å……)
    source_padding_mask = torch.zeros_like(source_ids, dtype=torch.bool)
    source_padding_mask[:, -5:] = True  # æœ€å5ä¸ªä½ç½®æ˜¯å¡«å……
    
    # åˆ›å»ºæ ‡ç­¾ (æŠŠtarget_idså‘å³åç§»ï¼Œæœ€åä¸€ä¸ªæ˜¯å¡«å……)
    labels = torch.cat([target_ids[:, 1:], torch.zeros((batch_size, 1), dtype=torch.long)], dim=1)
    
    # æŠŠä¸€äº›ä½ç½®è®¾ä¸ºpadding (ä¸ºäº†æµ‹è¯•æ©ç )
    pad_positions = torch.randint(0, target_len, (batch_size, 3))
    for i in range(batch_size):
        labels[i, pad_positions[i]] = 0
    
    return {
        'source_ids': source_ids,
        'target_ids': target_ids,
        'source_padding_mask': source_padding_mask,
        'labels': labels
    }

def mock_evaluation_logic(logits, gate_weights, labels, pad_token_id=0):
    """æ¨¡æ‹Ÿè¯„ä¼°å‡½æ•°ä¸­çš„é—¨æ§æƒé‡å¤„ç†é€»è¾‘"""
    print(f"âš¡ æµ‹è¯•è¯„ä¼°é€»è¾‘...")
    print(f"  - logits å½¢çŠ¶: {logits.shape}")
    print(f"  - gate_weights å½¢çŠ¶: {gate_weights.shape}")
    print(f"  - labels å½¢çŠ¶: {labels.shape}")
    
    # 1. åˆ›å»ºä¸€ä¸ªæ©ç ï¼Œæ ‡è¯†å“ªäº›ä½ç½®æ˜¯æœ‰æ•ˆæ ‡ç­¾ï¼ˆépadï¼‰
    label_mask = (labels != pad_token_id).float().unsqueeze(-1)  # [B, T, 1]
    print(f"  - label_mask å½¢çŠ¶: {label_mask.shape}")
    
    # 2. åº”ç”¨æ©ç ï¼Œåªè€ƒè™‘æœ‰æ•ˆä½ç½®çš„æƒé‡
    valid_gate_weights = gate_weights * label_mask
    print(f"  - valid_gate_weights å½¢çŠ¶: {valid_gate_weights.shape}")
    
    # 3. å¯¹æ¯ä¸ªbatchçš„æœ‰æ•ˆä½ç½®å–å¹³å‡
    batch_sum = valid_gate_weights.sum(dim=1)  # [B, num_experts]
    batch_count = label_mask.sum(dim=1)  # [B, 1]
    # é˜²æ­¢é™¤é›¶
    batch_mean = batch_sum / (batch_count + 1e-8)  # [B, num_experts]
    print(f"  - batch_mean å½¢çŠ¶: {batch_mean.shape}")
    
    # 4. å†å¯¹æ•´ä¸ªbatchå–å¹³å‡å¾—åˆ°æœ€ç»ˆæƒé‡
    masked_gate_weights = batch_mean.mean(dim=0)  # [num_experts]
    print(f"  - masked_gate_weights å½¢çŠ¶: {masked_gate_weights.shape}")
    print(f"  - ä¸“å®¶æƒé‡: {masked_gate_weights.detach().cpu().numpy()}")
    
    return masked_gate_weights

def validate_fixes():
    """éªŒè¯ä¿®å¤æ˜¯å¦æœ‰æ•ˆ"""
    print("ğŸ§ª å¼€å§‹éªŒè¯é—¨æ§ç½‘ç»œç»´åº¦ä¿®å¤...")
    
    # 1. åŠ è½½é…ç½®
    config = get_config()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 2. åˆ›å»ºæ¨¡å‹é…ç½®
    encoder_config = {
        'item_num': 10000,
        'max_len': 64,
        'embedding_dim': 64,
        'linear_hidden_dim': 16,
        'attention_dim': 16,
        'num_layers': 2,
        'num_heads': 2,
        'dropout': 0.1,
        'pad_token_id': 0,
    }
    
    decoder_config = {
        'num_items': 10000,
        'embedding_dim': 64,
        'num_layers': 2,
        'num_heads': 2,
        'ffn_hidden_dim': 256,
        'max_seq_len': 20,
        'dropout_ratio': 0.1,
        'pad_token_id': 0,
    }
    
    expert_config = config['expert_system']
    
    # 3. åˆå§‹åŒ–æ¨¡å‹ - åªå¯ç”¨è¡Œä¸ºä¸“å®¶ä»¥é¿å…åŠ è½½åµŒå…¥çŸ©é˜µ
    modified_expert_config = expert_config.copy()
    # ç¦ç”¨å†…å®¹ä¸“å®¶å’Œå›¾åƒä¸“å®¶ï¼Œåªä¿ç•™è¡Œä¸ºä¸“å®¶è¿›è¡Œæµ‹è¯•
    modified_expert_config['enable_content_expert'] = False
    modified_expert_config['enable_image_expert'] = False
    modified_expert_config['enable_behavior_expert'] = True
    
    model = GENIUSRecModel(encoder_config, decoder_config, modified_expert_config)
    model.to(device)
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    
    print("\nğŸ“‹ æ¨¡å‹é…ç½®æ‘˜è¦:")
    print(f"  - ç¼–ç å™¨åºåˆ—é•¿åº¦: {encoder_config['max_len']}")
    print(f"  - è§£ç å™¨åºåˆ—é•¿åº¦: {decoder_config['max_seq_len']}")
    print(f"  - å¯ç”¨çš„ä¸“å®¶: {model.decoder.enabled_experts}")
    
    # åŠ è½½å¿…è¦çš„åµŒå…¥çŸ©é˜µæˆ–ç¦ç”¨ç›¸åº”çš„ä¸“å®¶
    print("\nğŸ”§ å‡†å¤‡ä¸“å®¶ç³»ç»Ÿ...")
    
    # ç®€å•æ–¹æ¡ˆï¼šä¸ºæµ‹è¯•ç›®çš„ç¦ç”¨å†…å®¹å’Œå›¾åƒä¸“å®¶ï¼Œåªä¿ç•™è¡Œä¸ºä¸“å®¶
    if 'content_expert' in model.decoder.enabled_experts:
        print("  - ä¸ºæµ‹è¯•ç›®çš„ç¦ç”¨å†…å®¹ä¸“å®¶")
        model.decoder.expert_config['experts']['content_expert'] = False
        model.decoder.enabled_experts = [k for k, v in model.decoder.expert_config["experts"].items() if v]
    
    if 'image_expert' in model.decoder.enabled_experts:
        print("  - ä¸ºæµ‹è¯•ç›®çš„ç¦ç”¨å›¾åƒä¸“å®¶")
        model.decoder.expert_config['experts']['image_expert'] = False
        model.decoder.enabled_experts = [k for k, v in model.decoder.expert_config["experts"].items() if v]
    
    print(f"  - æµ‹è¯•å°†ä½¿ç”¨çš„ä¸“å®¶: {model.decoder.enabled_experts}")
    
    # 4. åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = create_test_data(
        batch_size=2, 
        source_len=encoder_config['max_len'],
        target_len=decoder_config['max_seq_len'],
        embedding_dim=encoder_config['embedding_dim']
    )
    
    # è½¬ç§»æ•°æ®åˆ°è®¾å¤‡
    for key in test_data:
        test_data[key] = test_data[key].to(device)
    
    print("\nğŸ“Š æµ‹è¯•æ•°æ®å½¢çŠ¶:")
    for key, value in test_data.items():
        print(f"  - {key}: {value.shape}")
    
    # 5. æµ‹è¯•è®­ç»ƒæ¨¡å¼
    print("\nğŸ”„ æµ‹è¯•è®­ç»ƒæ¨¡å¼...")
    model.train()
    try:
        logits, gate_weights = model(
            test_data['source_ids'], 
            test_data['target_ids'], 
            test_data['source_padding_mask'],
            return_weights=True
        )
        print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
        print(f"  - logits å½¢çŠ¶: {logits.shape}")
        print(f"  - gate_weights å½¢çŠ¶: {gate_weights.shape}")
        
        # æ¨¡æ‹ŸæŸå¤±è®¡ç®—
        mock_evaluation_logic(logits, gate_weights, test_data['labels'])
        print("  âœ… è®­ç»ƒæ¨¡å¼æµ‹è¯•é€šè¿‡!")
    except Exception as e:
        print(f"  âŒ è®­ç»ƒæ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    # 6. æµ‹è¯•è¯„ä¼°æ¨¡å¼
    print("\nğŸ” æµ‹è¯•è¯„ä¼°æ¨¡å¼...")
    model.eval()
    try:
        with torch.no_grad():
            logits, gate_weights = model(
                test_data['source_ids'], 
                test_data['target_ids'], 
                test_data['source_padding_mask'],
                return_weights=True
            )
        print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
        print(f"  - logits å½¢çŠ¶: {logits.shape}")
        print(f"  - gate_weights å½¢çŠ¶: {gate_weights.shape}")
        
        # æ¨¡æ‹Ÿè¯„ä¼°æµç¨‹
        mock_evaluation_logic(logits, gate_weights, test_data['labels'])
        print("  âœ… è¯„ä¼°æ¨¡å¼æµ‹è¯•é€šè¿‡!")
    except Exception as e:
        print(f"  âŒ è¯„ä¼°æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    # 7. ç‰¹åˆ«æµ‹è¯•ï¼šä¸åŒåºåˆ—é•¿åº¦çš„æƒ…å†µ
    print("\nğŸ§© æµ‹è¯•ä¸åŒåºåˆ—é•¿åº¦çš„æƒ…å†µ...")
    try:
        # åˆ›å»ºåºåˆ—é•¿åº¦ä¸åŒçš„æµ‹è¯•æ•°æ®
        special_test_data = create_test_data(
            batch_size=2, 
            source_len=50,  # ä¸ç¼–ç å™¨é…ç½®ä¸åŒ
            target_len=15,  # ä¸è§£ç å™¨é…ç½®ä¸åŒ
            embedding_dim=encoder_config['embedding_dim']
        )
        
        # è½¬ç§»æ•°æ®åˆ°è®¾å¤‡
        for key in special_test_data:
            special_test_data[key] = special_test_data[key].to(device)
            
        with torch.no_grad():
            logits, gate_weights = model(
                special_test_data['source_ids'], 
                special_test_data['target_ids'], 
                special_test_data['source_padding_mask'],
                return_weights=True
            )
        print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
        print(f"  - source_ids å½¢çŠ¶: {special_test_data['source_ids'].shape}")
        print(f"  - target_ids å½¢çŠ¶: {special_test_data['target_ids'].shape}")
        print(f"  - logits å½¢çŠ¶: {logits.shape}")
        print(f"  - gate_weights å½¢çŠ¶: {gate_weights.shape}")
        
        # æ¨¡æ‹Ÿè¯„ä¼°æµç¨‹
        mock_evaluation_logic(logits, gate_weights, special_test_data['labels'])
        print("  âœ… ä¸åŒåºåˆ—é•¿åº¦æµ‹è¯•é€šè¿‡!")
    except Exception as e:
        print(f"  âŒ ä¸åŒåºåˆ—é•¿åº¦æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! é—¨æ§ç½‘ç»œç»´åº¦ä¿®å¤æœ‰æ•ˆ!")
    return True

def test_evaluation_speed():
    """æµ‹è¯•ä¸åŒè¯„ä¼°æ¨¡å¼çš„é€Ÿåº¦å·®å¼‚"""
    import time
    from torch.utils.data import DataLoader, TensorDataset
    from src.unified_evaluation import evaluate_model_validation_with_ranking
    
    print("\nğŸš€ æµ‹è¯•è¯„ä¼°é€Ÿåº¦å·®å¼‚...")
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•é›†
    batch_size = 32
    source_len = 64
    target_len = 20
    embedding_dim = 64
    num_batches = 10  # å¾ˆå°çš„æµ‹è¯•é›†ï¼Œåªä¸ºäº†æ¼”ç¤º
    
    # 1. åŠ è½½é…ç½®
    config = get_config()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 2. åˆ›å»ºæ¨¡å‹é…ç½®
    encoder_config = {
        'item_num': 10000,
        'max_len': 64,
        'embedding_dim': 64,
        'linear_hidden_dim': 16,
        'attention_dim': 16,
        'num_layers': 2,
        'num_heads': 2,
        'dropout': 0.1,
        'pad_token_id': 0,
    }
    
    decoder_config = {
        'num_items': 10000,
        'embedding_dim': 64,
        'num_layers': 2,
        'num_heads': 2,
        'ffn_hidden_dim': 256,
        'max_seq_len': 20,
        'dropout_ratio': 0.1,
        'pad_token_id': 0,
    }
    
    # ç¦ç”¨å†…å®¹å’Œå›¾åƒä¸“å®¶ï¼Œåªä¿ç•™è¡Œä¸ºä¸“å®¶
    expert_config = config['expert_system'].copy()
    expert_config['enable_content_expert'] = False
    expert_config['enable_image_expert'] = False
    expert_config['enable_behavior_expert'] = True
    
    # 3. åˆ›å»ºæ¨¡å‹
    model = GENIUSRecModel(encoder_config, decoder_config, expert_config)
    model.to(device)
    model.eval()
    
    # 4. åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = []
    for _ in range(num_batches):
        batch_data = create_test_data(
            batch_size=batch_size, 
            source_len=source_len,
            target_len=target_len
        )
        for key in batch_data:
            batch_data[key] = batch_data[key].to(device)
        test_data.append(batch_data)
    
    # 5. åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®åŠ è½½å™¨
    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)
    
    # 6. æµ‹è¯•ä¸åŒå€™é€‰é›†å¤§å°çš„è¯„ä¼°é€Ÿåº¦
    sample_sizes = [None, 1000, 500, 100]
    
    for sample_size in sample_sizes:
        start_time = time.time()
        mode_desc = "å…¨é‡è¯„ä¼°" if sample_size is None else f"é‡‡æ ·è¯„ä¼°({sample_size}å€™é€‰é¡¹)"
        print(f"\nğŸ“Š æµ‹è¯•æ¨¡å¼: {mode_desc}")
        
        # æ‰§è¡Œä¸€å°éƒ¨åˆ†è¯„ä¼°ä»¥æµ‹è¯•é€Ÿåº¦
        with torch.no_grad():
            for i, batch in enumerate(test_data):
                if i >= 2:  # åªæµ‹è¯•2ä¸ªæ‰¹æ¬¡ï¼ŒèŠ‚çº¦æ—¶é—´
                    break
                    
                source_ids = batch['source_ids']
                decoder_input_ids = batch['target_ids']
                labels = batch['labels']
                source_padding_mask = (source_ids == 0)
                
                # å‰å‘ä¼ æ’­
                logits, gate_weights = model(source_ids, decoder_input_ids, source_padding_mask, return_weights=True)
                
                # ç”¨æˆ·åµŒå…¥
                encoder_outputs = model.encoder(source_ids)  # [B, L, D]
                user_embeddings = encoder_outputs[:, -1, :]  # [B, D]
                
                # æ¨¡æ‹Ÿè¯„ä¼°è®¡ç®—
                if sample_size is None:
                    # å…¨é‡è¯„ä¼° - è®¡ç®—ä¸æ‰€æœ‰ç‰©å“çš„ç›¸ä¼¼åº¦
                    all_item_ids = torch.arange(1, 1000, device=device)  # æ¨¡æ‹Ÿè¾ƒå°çš„ç‰©å“é›†
                    all_item_embeddings = torch.randn(999, encoder_config['embedding_dim'], device=device)  # éšæœºåµŒå…¥
                    
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    scores = torch.matmul(user_embeddings, all_item_embeddings.t())  # [B, num_items]
                else:
                    # é‡‡æ ·è¯„ä¼° - éšæœºé€‰æ‹©sample_sizeä¸ªå€™é€‰ç‰©å“
                    for i in range(user_embeddings.size(0)):
                        candidate_ids = torch.randint(1, 1000, (sample_size,), device=device)  # éšæœºå€™é€‰ç‰©å“
                        candidate_embeddings = torch.randn(sample_size, encoder_config['embedding_dim'], device=device)  # éšæœºåµŒå…¥
                        
                        # è®¡ç®—ç›¸ä¼¼åº¦
                        scores = torch.matmul(user_embeddings[i:i+1], candidate_embeddings.t())  # [1, sample_size]
                
        elapsed_time = time.time() - start_time
        print(f"  â±ï¸ è¯„ä¼°è€—æ—¶: {elapsed_time:.4f}ç§’")
    
    print("\nğŸ’¡ ç»“è®º: é‡‡æ ·è¯„ä¼°å¯ä»¥å¤§å¤§åŠ é€Ÿè¯„ä¼°è¿‡ç¨‹ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡ç‰©å“é›†çš„æƒ…å†µä¸‹")
    print("   å»ºè®®: å¼€å‘è¿‡ç¨‹ä¸­ä½¿ç”¨é‡‡æ ·è¯„ä¼°ï¼ˆ100-500ä¸ªå€™é€‰é¡¹ï¼‰ï¼Œæœ€ç»ˆæµ‹è¯•ä½¿ç”¨å…¨é‡è¯„ä¼°")

if __name__ == "__main__":
    validate_fixes()
    # è¿è¡Œè¯„ä¼°é€Ÿåº¦æµ‹è¯•
    test_evaluation_speed()
