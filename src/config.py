# src/config.py (é‡æ„ç‰ˆ)

import torch
from pathlib import Path

def get_config():
    """
    è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰é¡¹ç›®é…ç½®çš„å­—å…¸ã€‚
    æ­¤ç‰ˆæœ¬ä¸ºæ”¯æŒEncoder-Decoderå¾®è°ƒè€Œé‡æ„ã€‚
    """
    ROOT_DIR = Path(__file__).parent.parent 
    
    config = {
        # =================================================================
        # 1. é€šç”¨ä¸è·¯å¾„é…ç½® (General & Path Config)
        # =================================================================
        "data": {
            "data_dir": ROOT_DIR / "data",
            "processed_data_dir": ROOT_DIR / "data" / "processed",
            "log_dir": ROOT_DIR / "logs",
            "checkpoint_dir": ROOT_DIR / "checkpoints",
            
            "train_file": ROOT_DIR / "data" / "processed" / "train.parquet",
            "validation_file": ROOT_DIR / "data" / "processed" / "validation.parquet",
            "test_file": ROOT_DIR / "data" / "processed" / "test.parquet",
            "id_maps_file": ROOT_DIR / "data" / "processed" / "id_maps.pkl",
        },
        
        "k_core": 5,
        "min_seq_len": 5,
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "seed": 42,
        "pad_token_id": 0,
        "sos_token_id": 1,  # ğŸ”§ æ–°å¢ï¼šæ˜ç¡®å®šä¹‰SOS token
        
        # =================================================================
        # 2. æ¨¡å‹è¶…å‚æ•°é…ç½® (Model Hyperparameters)
        # =================================================================
        "encoder_model": {
            "max_len": 50,
            "embedding_dim": 64,
            "linear_hidden_dim": 16, # dv
            "attention_dim": 16,     # dqk
            "num_layers": 4,
            "num_heads": 4,
            "dropout": 0.1,
            # item_num å’Œ pad_token_id åœ¨è®­ç»ƒè„šæœ¬ä¸­åŠ¨æ€ä¼ å…¥
        },

        "decoder_model": {
            "max_seq_len": 50, # è§£ç å™¨ä¹Ÿéœ€è¦çŸ¥é“æœ€å¤§é•¿åº¦
            "embedding_dim": 64, # ç»´åº¦é€šå¸¸ä¸ç¼–ç å™¨ä¿æŒä¸€è‡´
            "num_layers": 4,     # è§£ç å™¨å±‚æ•°ï¼Œå¯ä»¥ä¸ç¼–ç å™¨ä¸åŒ
            "num_heads": 4,
            "ffn_hidden_dim": 64 * 4, # å‰é¦ˆç½‘ç»œéšè—å±‚ç»´åº¦ï¼Œé€šå¸¸æ˜¯embedding_dimçš„4å€
            "dropout_ratio": 0.3,
             # num_items åœ¨è®­ç»ƒè„šæœ¬ä¸­åŠ¨æ€ä¼ å…¥
        },

        # =================================================================
        # 3. è®­ç»ƒé˜¶æ®µé…ç½® (Training Phase Config)
        # =================================================================
        
        # --- é˜¶æ®µä¸€: ç¼–ç å™¨é¢„è®­ç»ƒé…ç½® ---
        "pretrain": {
            "log_file": "pretrain_encoder.log",
            "num_epochs": 501,         
            "batch_size": 256,         
            "learning_rate": 1e-3,
            "weight_decay": 0.3,
            "early_stopping_patience": 20,
            "num_workers": 10,
            "num_neg_samples": 512, # è´Ÿé‡‡æ ·æ•°é‡
            "temperature": 0.05,    # Sampled Softmaxæ¸©åº¦
        },
        
        # --- é˜¶æ®µäºŒ: Encoder-Decoder å¾®è°ƒé…ç½® ---
        "finetune": {
            "log_file": "finetune_genius_rec.log",
            "num_epochs": 50, # å¾®è°ƒé€šå¸¸ä¸éœ€è¦å¤ªå¤šè½®æ¬¡
            "batch_size": 64, # ç”±äºæ¨¡å‹æ›´å¤§ï¼Œå¯èƒ½éœ€è¦å‡å°batch_size
            "learning_rate": {
                "decoder_lr": 1e-3, # è§£ç å™¨ä½¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡
                "encoder_lr": 5e-6, # ç¼–ç å™¨ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡
            },
            "label_smoothing": 0, # æ ‡ç­¾å¹³æ»‘ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
            "warmup_steps": 1000, # å­¦ä¹ ç‡é¢„çƒ­æ­¥æ•°
            "weight_decay": 0.1,
            "early_stopping_patience": 5,
            "num_workers": 10,
            "split_ratio": 0.5, # æ•°æ®é›†åˆ†å‰²æ¯”ä¾‹
            "warmup_epochs": 3, # é¢„çƒ­è½®æ¬¡
        },
        
        # =================================================================
        # 4. è¯„ä¼°å‚æ•° (Evaluation Config)
        # =================================================================
        "evaluation": {
            "top_k": 10,
        },
        
        # =================================================================
        # 5. ä¸“å®¶ç³»ç»Ÿé…ç½® (Expert System Config) ã€æ–°å¢ã€‘
        # =================================================================
        "expert_system": {
            # ä¸“å®¶å¯ç”¨å¼€å…³
            "experts": {
                "behavior_expert": True,     # è¡Œä¸ºä¸“å®¶ï¼ˆåŸºäºç”¨æˆ·åºåˆ—è¡Œä¸ºï¼‰
                "content_expert": True,      # å†…å®¹ä¸“å®¶ï¼ˆåŸºäºæ–‡æœ¬åµŒå…¥ï¼‰
                "image_expert": True,        # å›¾åƒä¸“å®¶ï¼ˆåŸºäºä¹¦å°é¢ï¼‰ğŸ¨ å¯ç”¨è§†è§‰ä¸“å®¶ï¼
            },
            
            # é—¨æ§ç½‘ç»œé…ç½®
            "gate_config": {
                "gate_type": "simple",       # é—¨æ§ç±»å‹ï¼š'simple'(åŸå§‹), 'mlp'(æ–°å¢)
                "gate_hidden_dim": 64,       # MLPé—¨æ§çš„éšè—å±‚ç»´åº¦ï¼ˆä»…gate_type='mlp'æ—¶ä½¿ç”¨ï¼‰
                "temperature": 1.0,          # softmaxæ¸©åº¦å‚æ•°ï¼ˆé¢„ç•™ï¼‰
            },
            
            # å†…å®¹ä¸“å®¶é…ç½®
            "content_expert": {
                "attention_heads": 4,        # äº¤å‰æ³¨æ„åŠ›å¤´æ•°
                "use_cross_attention": True, # æ˜¯å¦ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›
                "text_embedding_dim": 768,   # æ–‡æœ¬åµŒå…¥ç»´åº¦
            },
            
            # å›¾åƒä¸“å®¶é…ç½®
            "image_expert": {
                "attention_heads": 4,        # äº¤å‰æ³¨æ„åŠ›å¤´æ•°  
                "use_cross_attention": True, # æ˜¯å¦ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›
                "image_embedding_dim": 512,  # å›¾åƒåµŒå…¥ç»´åº¦ï¼ˆCLIP ViT-B/32ï¼‰
                "image_encoder": "clip",     # å›¾åƒç¼–ç å™¨ç±»å‹
                "use_adaptive_pooling": True, # ä½¿ç”¨è‡ªé€‚åº”æ± åŒ–é€‚é…ä¸åŒç»´åº¦
                "visual_attention_dropout": 0.1, # è§†è§‰æ³¨æ„åŠ›dropout
            }
        }
    }
    
    return config