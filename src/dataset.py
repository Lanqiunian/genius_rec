import pandas as pd
import numpy as np
import torch
from torch.utils.data import Dataset

class Seq2SeqRecDataset(Dataset):
    """
    ä¸ºGENIUS-Recæ¨¡å‹å‡†å¤‡è®­ç»ƒå’ŒéªŒè¯æ•°æ®çš„æ•°æ®é›†ã€‚
    æ ¸å¿ƒé€»è¾‘ï¼š
    1. åŠ¨æ€åˆ†å‰²ï¼šæ ¹æ®çœŸå®åºåˆ—é•¿åº¦å’Œé…ç½®ä¸­çš„æ¯”ä¾‹ï¼Œå°†ç”¨æˆ·å†å²åˆ†å‰²ä¸ºæº(source)å’Œç›®æ ‡(target)ã€‚
    2. å›ºå®šé•¿åº¦å¡«å……ï¼šå°†åˆ†å‰²åçš„åºåˆ—å¡«å……åˆ°é…ç½®ä¸­æŒ‡å®šçš„å›ºå®šé•¿åº¦ï¼Œä»¥ä¾¿è¿›è¡Œæ‰¹å¤„ç†ã€‚
    3. æ³¨å…¥ç‰¹æ®ŠTokenï¼šä¸ºè§£ç å™¨çš„è¾“å…¥æ·»åŠ [SOS]ï¼Œä¸ºæ ‡ç­¾æ·»åŠ [EOS]ã€‚
    """
    def __init__(self, config, data_path):
        """
        åˆå§‹åŒ–æ•°æ®é›†ã€‚

        Args:
            config (dict): å…¨å±€é…ç½®å­—å…¸ã€‚
            data_path (str or Path): æ•°æ®æ–‡ä»¶è·¯å¾„ (.parquetæ ¼å¼)ã€‚
        """
        self.data = pd.read_parquet(data_path)
        
        # --- ä»é…ç½®ä¸­è¯»å–æ‰€æœ‰å¿…è¦çš„å‚æ•° ---
        self.max_seq_len = config['encoder_model']['max_len']
        self.pad_token_id = config['pad_token_id']
        self.sos_token_id = config['sos_token_id']
        self.eos_token_id = config['eos_token_id']
        
        # ã€æœ€ç»ˆä¼˜åŒ–ã€‘è¯»å–çœŸæ­£ç”¨äºåºåˆ—åˆ†å‰²çš„æ¯”ä¾‹
        # è¿™ä¸ªæ¯”ä¾‹å†³å®šäº†ç”¨å¤šå°‘å†å²(e.g., 80%)å»é¢„æµ‹å¤šå°‘æœªæ¥(e.g., 20%)
        self.sequence_split_ratio = config['finetune'].get('split_ratio', 0.8) # æä¾›é»˜è®¤å€¼ä»¥å¢åŠ å¥å£®æ€§
        
        # ã€æœ€ç»ˆä¼˜åŒ–ã€‘è®¡ç®—ç¼–ç å™¨å’Œè§£ç å™¨è¾“å…¥æœ€ç»ˆéœ€è¦è¢«å¡«å……åˆ°çš„å›ºå®šé•¿åº¦
        # è¿™ç¡®ä¿äº†DataLoaderè¾“å‡ºçš„æ¯ä¸ªTensorå½¢çŠ¶éƒ½ä¸€è‡´
        self.encoder_target_len = int(self.max_seq_len * self.sequence_split_ratio)
        self.decoder_target_len = self.max_seq_len - self.encoder_target_len

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # 1. è·å–ä¸€ä¸ªç”¨æˆ·çš„å®Œæ•´å†å²åºåˆ—
        full_seq = self.data.iloc[idx]['history']
        
        # 2. æˆªæ–­è¿‡é•¿çš„åºåˆ—ï¼Œåªä¿ç•™æœ€è¿‘çš„è¡Œä¸º
        if len(full_seq) > self.max_seq_len:
            full_seq = full_seq[-self.max_seq_len:]
        
        # 3. åŠ¨æ€åˆ†å‰²åºåˆ—ï¼Œç”Ÿæˆæº(source)å’Œç›®æ ‡(target)
        if len(full_seq) <= 2:
            # å¤„ç†æçŸ­åºåˆ—çš„è¾¹ç¼˜æƒ…å†µ
            source_seq = [full_seq[0]] if len(full_seq) > 0 else []
            target_seq = full_seq[1:] if len(full_seq) > 1 else []
        else:
            # ä½¿ç”¨é…ç½®é©±åŠ¨çš„æ¯”ä¾‹ï¼ŒåŸºäºå½“å‰åºåˆ—çš„çœŸå®é•¿åº¦è¿›è¡Œåˆ†å‰²
            split_idx = max(1, int(len(full_seq) * self.sequence_split_ratio))
            source_seq = full_seq[:split_idx]
            target_seq = full_seq[split_idx:]

        # 4. åˆ›å»ºç¼–ç å™¨è¾“å…¥ï¼Œå¹¶è¿›è¡Œå·¦å¯¹é½å¡«å…… (å…³é”®ä¿®æ­£)
        source_ids = np.full(self.encoder_target_len, self.pad_token_id, dtype=np.int64)
        if len(source_seq) > 0:
            # ä»å·¦ä¾§å¼€å§‹å¡«å……çœŸå®åºåˆ—
            copy_len = min(len(source_seq), self.encoder_target_len)
            source_ids[:copy_len] = source_seq[:copy_len]

        # 5. åˆ›å»ºè§£ç å™¨è¾“å…¥ (decoder_input_ids)
        # æ ¼å¼: [SOS, item1, item2, ..., PAD, PAD]
        decoder_input_ids = np.full(self.decoder_target_len, self.pad_token_id, dtype=np.int64)
        decoder_input_ids[0] = self.sos_token_id  # åºåˆ—ä»¥[SOS]å¼€å§‹
        if len(target_seq) > 0: # æ£€æŸ¥éç©º
            copy_len = min(len(target_seq), self.decoder_target_len - 1)
            decoder_input_ids[1:1+copy_len] = target_seq[:copy_len]

        # 6. åˆ›å»ºè§£ç å™¨æ ‡ç­¾ (labels)
        # æ ¼å¼: [item1, item2, item3, ..., EOS, PAD]
        labels = np.full(self.decoder_target_len, self.pad_token_id, dtype=np.int64)
        if len(target_seq) > 0: # æ£€æŸ¥éç©º
            copy_len = min(len(target_seq), self.decoder_target_len - 1)
            labels[:copy_len] = target_seq[:copy_len]
            # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿EOS tokenä½ç½®å®‰å…¨ï¼Œå¹¶ä¸”ç´§è·Ÿåœ¨å®é™…å†…å®¹å
            eos_position = copy_len
            if eos_position < self.decoder_target_len:
                labels[eos_position] = self.eos_token_id
        
        return {
            'source_ids': torch.tensor(source_ids, dtype=torch.long),
            'decoder_input_ids': torch.tensor(decoder_input_ids, dtype=torch.long),
            'labels': torch.tensor(labels, dtype=torch.long)
        }