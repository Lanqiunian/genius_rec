import argparse
import logging
import os
import pickle
import random
import math
from tqdm import tqdm
import pathlib
from transformers import get_linear_schedule_with_warmup

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset

from src.config import get_config
from src.GeniusRec import GENIUSRecModel
from src.dataset import Seq2SeqRecDataset

import platform

# python -m src.train_GeniusRec --encoder_weights_path checkpoints/hstu_encoder.pth --freeze_encoder
def train_one_epoch(model, dataloader, criterion, optimizer, scheduler, device, epoch, num_epochs, pad_token_id):
    """
    ã€å·²ä¿®æ”¹ã€‘: æ–°å¢ scheduler å‚æ•°å’Œ pad_token_id å‚æ•°, å¹¶åœ¨æ¯ä¸ªbatchåè°ƒç”¨ scheduler.step()
    """
    model.train()
    total_loss = 0.0
    progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs} [Training]")

    for batch in progress_bar:
        source_ids = batch['source_ids'].to(device)
        decoder_input_ids = batch['decoder_input_ids'].to(device)
        labels = batch['labels'].to(device)
        source_padding_mask = (source_ids == pad_token_id).to(device)
        optimizer.zero_grad()
        
        # æ¨¡å‹å‰å‘ä¼ æ’­
        logits = model(source_ids, decoder_input_ids, source_padding_mask)

        # è®¡ç®—æŸå¤±
        loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))
        
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # æ¢¯åº¦è£å‰ª
        optimizer.step()
        
        # åœ¨æ¯ä¸ªbatchåæ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        total_loss += loss.item()
        progress_bar.set_postfix(loss=loss.item(), avg_loss=total_loss/len(progress_bar))
        
    return total_loss / len(dataloader)

def evaluate(model, dataloader, criterion, device, epoch, num_epochs, pad_token_id):
    model.eval()
    total_loss = 0.0
    progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs} [Validation]")

    with torch.no_grad():
        for batch in progress_bar:
            source_ids = batch['source_ids'].to(device)
            decoder_input_ids = batch['decoder_input_ids'].to(device)
            labels = batch['labels'].to(device)
            source_padding_mask = (source_ids == pad_token_id).to(device)

            logits = model(source_ids, decoder_input_ids, source_padding_mask)
            loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))
            
            total_loss += loss.item()
            progress_bar.set_postfix(loss=loss.item(), avg_loss=total_loss/len(progress_bar))

    avg_loss = total_loss / len(dataloader)
    perplexity = math.exp(avg_loss)
    return avg_loss, perplexity


# --- 2. ä¸»å‡½æ•° (å·²ä¿®æ”¹è°ƒåº¦å™¨é€»è¾‘) ---
def main():
    parser = argparse.ArgumentParser(description="Fine-tuning script for GENIUS-Rec model.")
    parser.add_argument('--config_path', type=str, help='Path to your project config file (optional).')
    parser.add_argument('--encoder_weights_path', type=str, required=True, help='Path to pre-trained HSTU encoder weights.')
    parser.add_argument('--freeze_encoder', action='store_true', help='Freeze encoder weights during fine-tuning.')
    parser.add_argument('--save_dir', type=str, default='checkpoints/checkpoints_genius_rec', help='Directory to save fine-tuned models.')
    args = parser.parse_args()

    # --- åˆå§‹åŒ– ---
    config = get_config()
    device = torch.device(config['device'])
    random.seed(config['seed'])
    np.random.seed(config['seed'])
    torch.manual_seed(config['seed'])
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(config['seed'])

    os.makedirs(args.save_dir, exist_ok=True)
    log_dir_path = pathlib.Path(config['data']['log_dir'])
    log_dir_path.mkdir(parents=True, exist_ok=True)
    log_file = log_dir_path / config['finetune']['log_file']
    logging.basicConfig(level=logging.INFO,
                        format='%(asctime)s - %(levelname)s - %(message)s',
                        handlers=[logging.FileHandler(log_file), logging.StreamHandler()])

    logging.info("--- Starting GENIUS-Rec Fine-tuning with Warmup Scheduler ---")
    logging.info(f"Device: {device}")
    logging.info(f"Arguments: {args}")

    # --- å‡†å¤‡æ•°æ® ---
    with open(config['data']['id_maps_file'], 'rb') as f:
        id_maps = pickle.load(f)
        num_items = id_maps['num_items'] + 1

    # ä¿®æ”¹æ•°æ®é›†åˆå§‹åŒ–
    train_dataset = Seq2SeqRecDataset(
        config['data']['train_file'], 
        config['decoder_model']['max_seq_len'], 
        pad_token_id=config['pad_token_id'],
        split_ratio=config['finetune']['split_ratio']
    )
    val_dataset = Seq2SeqRecDataset(
        config['data']['validation_file'], 
        config['decoder_model']['max_seq_len'], 
        pad_token_id=config['pad_token_id'],
        split_ratio=config['finetune']['split_ratio']
    )
    train_loader = DataLoader(train_dataset, batch_size=config['finetune']['batch_size'], shuffle=True, num_workers=config['finetune']['num_workers'])
    val_loader = DataLoader(val_dataset, batch_size=config['finetune']['batch_size'], shuffle=False, num_workers=config['finetune']['num_workers'])
    logging.info(f"Data loaded. Training set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}")

    # --- æ„å»ºæ¨¡å‹ ---
    encoder_config = {**config['encoder_model'], 'item_num': num_items, 'pad_token_id': config['pad_token_id']}
    decoder_config = {
        **config['decoder_model'], 
        'num_items': num_items,
        'pad_token_id': config['pad_token_id']
    }
    model = GENIUSRecModel(encoder_config=encoder_config, decoder_config=decoder_config).to(device)
    logging.info("GENIUS-Rec model created.")

    # --- åŠ è½½é¢„è®­ç»ƒæƒé‡ (åŒ…å«è·¨å¹³å°è¡¥ä¸) ---
    logging.info(f"Loading pre-trained encoder weights from: {args.encoder_weights_path}")
    if platform.system() == "Linux" and os.path.exists(args.encoder_weights_path):
        temp_windows_path = getattr(pathlib, 'WindowsPath', None)
        pathlib.WindowsPath = pathlib.PosixPath
    
    encoder_state_dict = torch.load(args.encoder_weights_path, map_location=device)
    
    if platform.system() == "Linux" and 'temp_windows_path' in locals():
        pathlib.WindowsPath = temp_windows_path
    
    model.encoder.load_state_dict(encoder_state_dict, strict=False) 
    logging.info("Encoder weights loaded successfully.")
    
    # --- å†»ç»“ä¸ä¼˜åŒ–å™¨è®¾ç½® ---
    if args.freeze_encoder:
        logging.info("Freezing encoder parameters.")
        for param in model.encoder.parameters():
            param.requires_grad = False
        optimizer = torch.optim.AdamW(model.decoder.parameters(), lr=config['finetune']['learning_rate']['decoder_lr'], weight_decay=config['finetune']['weight_decay'])
    else:
        logging.info("Fine-tuning both encoder and decoder with different learning rates.")
        optimizer = torch.optim.AdamW([
            {'params': model.decoder.parameters(), 'lr': config['finetune']['learning_rate']['decoder_lr']},
            {'params': model.encoder.parameters(), 'lr': config['finetune']['learning_rate']['encoder_lr']}
        ], weight_decay=config['finetune']['weight_decay'])
        
    criterion = nn.CrossEntropyLoss(ignore_index=config['pad_token_id'])
    
    # --- ã€æ ¸å¿ƒä¿®æ”¹ã€‘: è®¾ç½®æ–°çš„å­¦ä¹ ç‡è°ƒåº¦å™¨ ---
    num_training_steps = len(train_loader) * config['finetune']['num_epochs']
    num_warmup_steps = config['finetune'].get('warmup_steps', 500) # ä»é…ç½®è·å–ï¼Œæä¾›é»˜è®¤å€¼
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=num_warmup_steps,
        num_training_steps=num_training_steps
    )
    logging.info(f"Using learning rate scheduler with {num_warmup_steps} warmup steps and {num_training_steps} total training steps.")

    # --- æ–­ç‚¹ç»­ä¼ é€»è¾‘ ---
    start_epoch = 0
    best_perplexity = float('inf')
    patience_counter = 0
    latest_ckpt_path = os.path.join(args.save_dir, 'genius_rec_latest.pth')
    best_ckpt_path = os.path.join(args.save_dir, 'genius_rec_best.pth')
    
    if os.path.exists(latest_ckpt_path):
        logging.info(f"å‘ç°æœ€æ–°æ£€æŸ¥ç‚¹: {latest_ckpt_path}ï¼Œæ­£åœ¨åŠ è½½...")
        try:
            checkpoint = torch.load(latest_ckpt_path, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            # ã€é‡è¦ã€‘: åŒæ ·éœ€è¦åŠ è½½è°ƒåº¦å™¨çš„çŠ¶æ€
            if 'scheduler_state_dict' in checkpoint:
                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            
            start_epoch = checkpoint['epoch'] + 1
            best_perplexity = checkpoint.get('best_perplexity', float('inf'))
            patience_counter = checkpoint.get('patience_counter', 0)
            logging.info(f"æˆåŠŸåŠ è½½æ£€æŸ¥ç‚¹! ä» Epoch {start_epoch} ç»§ç»­è®­ç»ƒ")
        except Exception as e:
            logging.warning(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}. å°†ä»å¤´å¼€å§‹è®­ç»ƒ")
            start_epoch = 0

    # --- è®­ç»ƒå¾ªç¯ ---
    for epoch in range(start_epoch, config['finetune']['num_epochs']):
        # ã€ä¿®æ”¹ã€‘: ä¼ å…¥schedulerå’Œpad_token_id
        avg_train_loss = train_one_epoch(model, train_loader, criterion, optimizer, scheduler, device, epoch, config['finetune']['num_epochs'], config['pad_token_id'])
        avg_val_loss, perplexity = evaluate(model, val_loader, criterion, device, epoch, config['finetune']['num_epochs'], config['pad_token_id'])
        
        logging.info(f"Epoch {epoch+1}/{config['finetune']['num_epochs']} - Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Perplexity: {perplexity:.4f}")
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        checkpoint_data = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'best_perplexity': best_perplexity,
            'current_perplexity': perplexity,
            'patience_counter': patience_counter,
        }
        torch.save(checkpoint_data, latest_ckpt_path)
        
        if perplexity < best_perplexity:
            best_perplexity = perplexity
            patience_counter = 0
            torch.save(checkpoint_data, best_ckpt_path)
            logging.info(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³æ¨¡å‹! å›°æƒ‘åº¦: {best_perplexity:.4f}. å·²ä¿å­˜è‡³ {best_ckpt_path}")
        else:
            patience_counter += 1
            logging.info(f"æ€§èƒ½æœªæå‡ï¼Œè€å¿ƒè®¡æ•°: {patience_counter}/{config['finetune']['early_stopping_patience']}")
            if patience_counter >= config['finetune']['early_stopping_patience']:
                logging.info(f"è§¦å‘æ—©åœ! è¿ç»­ {patience_counter} ä¸ªepochæ€§èƒ½æœªæå‡")
                break
                
    logging.info("--- Fine-tuning finished ---")
    completed_epochs = epoch + 1 if 'epoch' in locals() else start_epoch
    logging.info(f"è®­ç»ƒæ€»è½®æ¬¡: {completed_epochs}/{config['finetune']['num_epochs']}")
    logging.info(f"æœ€ä½³éªŒè¯å›°æƒ‘åº¦: {best_perplexity:.4f}")

if __name__ == '__main__':
    main()
