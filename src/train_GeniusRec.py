# src/train_GeniusRec.py
import argparse
import logging
import os
import pickle
import random
import math
import pathlib
import platform
from pathlib import Path

os.environ['CUDA_LAUNCH_BLOCKING'] = "1" # For precise error localization

os.environ['CUDA_LAUNCH_BLOCKING'] = "1" # For precise error localization

from tqdm import tqdm
from transformers import get_linear_schedule_with_warmup
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset

from src.config import get_config
from src.GeniusRec import GENIUSRecModel
from src.dataset import Seq2SeqRecDataset
from src.unified_evaluation import (
    ValidationDataset, 
    evaluate_model_test, 
    evaluate_model_validation_with_ranking
)

from src.encoder.encoder import Hstu
from src.decoder.decoder import GenerativeDecoder


# # ç«¯åˆ°ç«¯å¾®è°ƒè®­ç»ƒï¼ˆæ¨èæ–¹å¼ï¼‰
# python -m src.train_GeniusRec --encoder_weights_path checkpoints/hstu_encoder.pth --full_evaluation

# # å†»ç»“ç¼–ç å™¨è®­ç»ƒï¼ˆå¯¹æ¯”å®éªŒï¼‰
# python -m src.train_GeniusRec --encoder_weights_path checkpoints/hstu_encoder.pth --freeze_encoder

# # ä½¿ç”¨ä¸HSTUå®Œå…¨ä¸€è‡´çš„å…¨é‡è¯„ä¼°æ¨¡å¼ï¼ˆè¯„ä¼°æ‰€æœ‰ç‰©å“ï¼‰
# python -m src.train_GeniusRec --encoder_weights_path checkpoints/hstu_encoder.pth --full_evaluation

# # æˆ–è€…ä½¿ç”¨é‡‡æ ·è¯„ä¼°ï¼ˆé€Ÿåº¦æ›´å¿«ï¼ŒæŒ‡å®šå€™é€‰ç‰©å“æ•°é‡ï¼‰
# python -m src.train_GeniusRec --encoder_weights_path checkpoints/hstu_encoder.pth --sample_eval_size 1000

# # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
# python -m src.train_GeniusRec --resume_from checkpoints/genius_rec_moe_latest.pth --encoder_weights_path checkpoints/hstu_encoder.pth

# # è‡ªå®šä¹‰ä¿å­˜ç›®å½•
# python -m src.train_GeniusRec --save_dir my_checkpoints


def train_one_epoch(model, dataloader, criterion, optimizer, scheduler, device, epoch, num_epochs, pad_token_id, config, scaler=None):
    """è®­ç»ƒä¸€ä¸ªepochçš„å¾ªç¯ã€‚"""
    model.train()
    total_loss_value = 0.0
    progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs} [Training]", leave=True)

    balancing_loss_alpha = config['finetune'].get('balancing_loss_alpha', 0.01)

    for batch_idx, batch in enumerate(progress_bar):
        source_ids = batch['source_ids'].to(device)
        decoder_input_ids = batch['decoder_input_ids'].to(device)
        labels = batch['labels'].to(device)
        
        source_padding_mask = (source_ids == pad_token_id)
        target_padding_mask = (decoder_input_ids == pad_token_id)

        optimizer.zero_grad()

        with torch.amp.autocast('cuda', enabled=(scaler is not None)):
            logits, gate_weights, balancing_loss, _ = model(
                source_ids=source_ids,
                decoder_input_ids=decoder_input_ids,
                source_padding_mask=source_padding_mask,
                target_padding_mask=target_padding_mask,
                item_embedding_layer=model.encoder.item_embedding,
                return_weights=True
            )
            
            task_loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))
                
            if balancing_loss is not None:
                loss = task_loss + balancing_loss_alpha * balancing_loss
                bal_loss_item = balancing_loss.item()
            else:
                loss = task_loss
                bal_loss_item = 0.0

        if scaler is not None:
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            scaler.step(optimizer)
            scaler.update()
        else:
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
        
        if scheduler is not None:
             scheduler.step()
        
        total_loss_value += loss.item()
        
        if gate_weights is not None:
            enabled_experts = [k for k, v in model.decoder.expert_config["experts"].items() if v]
            weights_postfix = {}
            for i, expert_name in enumerate(enabled_experts):
                if i < gate_weights.shape[-1]:
                    display_name = f'{expert_name.split("_")[0][:3].title()}W'
                    weights_postfix[display_name] = f"{gate_weights[:, :, i].mean().item():.3f}"
            
            progress_bar.set_postfix({
                'loss': f"{loss.item():.4f}", 'task_l': f"{task_loss.item():.4f}",
                'bal_l': f"{bal_loss_item:.4f}", **weights_postfix
            })

    avg_loss = total_loss_value / len(dataloader)
    logging.info(f"Epoch {epoch+1} training finished. Average Loss: {avg_loss:.4f}")
    return avg_loss

def load_checkpoint(checkpoint_path, model, optimizer, scheduler, device):
    """
    æ£€æŸ¥ç‚¹åŠ è½½å‡½æ•°ï¼Œæ”¯æŒå®Œæ•´æ£€æŸ¥ç‚¹å’Œä»…æƒé‡çš„.pthæ–‡ä»¶
    
    Returns:
        dict: åŒ…å«æ¢å¤ä¿¡æ¯çš„å­—å…¸
    """
    logging.info(f"å°è¯•åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå®Œæ•´æ£€æŸ¥ç‚¹æ ¼å¼
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            # å®Œæ•´æ£€æŸ¥ç‚¹
            logging.info("æ£€æµ‹åˆ°å®Œæ•´æ£€æŸ¥ç‚¹æ ¼å¼")
            
            # åŠ è½½æ¨¡å‹æƒé‡
            model.load_state_dict(checkpoint['model_state_dict'])
            
            # å°è¯•åŠ è½½optimizerçŠ¶æ€
            if 'optimizer_state_dict' in checkpoint and optimizer is not None:
                try:
                    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                    logging.info("æˆåŠŸæ¢å¤optimizerçŠ¶æ€")
                except Exception as e:
                    logging.warning(f"æ— æ³•æ¢å¤optimizerçŠ¶æ€: {e}")
            
            # å°è¯•åŠ è½½schedulerçŠ¶æ€
            if 'scheduler_state_dict' in checkpoint and scheduler is not None:
                try:
                    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
                    logging.info("æˆåŠŸæ¢å¤schedulerçŠ¶æ€")
                except Exception as e:
                    logging.warning(f"æ— æ³•æ¢å¤schedulerçŠ¶æ€: {e}")
            
            return {
                'epoch': checkpoint.get('epoch', 0),
                'best_val_loss': checkpoint.get('best_val_loss', float('inf')),
                'val_loss': checkpoint.get('val_loss', float('inf')),
                'val_ppl': checkpoint.get('val_ppl', float('inf')),
                'patience_counter': checkpoint.get('patience_counter', 0)
            }
            
        else:
            # ä»…æƒé‡çš„æ£€æŸ¥ç‚¹
            logging.info("æ£€æµ‹åˆ°æƒé‡æ ¼å¼ï¼Œä»…æ¢å¤æ¨¡å‹æƒé‡")
            
            # å¤„ç†å¯èƒ½çš„é”®åä¸åŒ¹é…
            if hasattr(checkpoint, 'keys'):
                # å¦‚æœæ˜¯state_dictæ ¼å¼
                model.load_state_dict(checkpoint, strict=False)
            else:
                # å¦‚æœæ˜¯ç›´æ¥çš„æƒé‡
                logging.warning("æ— æ³•è¯†åˆ«çš„æ£€æŸ¥ç‚¹æ ¼å¼ï¼Œè·³è¿‡åŠ è½½")
                return None
            
            return {
                'epoch': 0,
                'best_val_loss': float('inf'),
                'val_loss': float('inf'),
                'val_ppl': float('inf'),
                'patience_counter': 0
            }
            
    except Exception as e:
        logging.error(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        return None

def save_checkpoint(checkpoint_path, model, optimizer, scheduler, epoch, metrics_dict, config, num_items):
    """
    æ£€æŸ¥ç‚¹ä¿å­˜å‡½æ•°ï¼Œä¿å­˜å®Œæ•´çš„è®­ç»ƒçŠ¶æ€
    """
    checkpoint_data = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict() if optimizer else None,
        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
        'config': config,
        'num_items': num_items,
        **metrics_dict  # å±•å¼€æ‰€æœ‰æŒ‡æ ‡
    }
    torch.save(checkpoint_data, checkpoint_path)


def main():
    # 1. å‚æ•°è§£æå’Œé…ç½®åŠ è½½
    parser = argparse.ArgumentParser(description="Train GENIUS-Rec Model")
    parser.add_argument('--encoder_weights_path', type=str, default=None, help='Path to pre-trained HSTU encoder weights.')
    parser.add_argument('--freeze_encoder', action='store_true', help='Freeze encoder weights.')
    parser.add_argument('--resume_from', type=str, default=None, help='Path to checkpoint to resume from.')
    parser.add_argument('--save_dir', type=str, default=None, help='Directory to save checkpoints.')
    parser.add_argument('--disable_behavior_expert', action='store_true', help='Disable behavior expert.')
    parser.add_argument('--disable_content_expert', action='store_true', help='Disable content expert.')
    parser.add_argument('--disable_image_expert', action='store_true', help='Disable image expert.')
    parser.add_argument('--enable_image_expert', action='store_true', help='Enable image expert (requires image embeddings).')
    parser.add_argument('--image_embeddings_path', type=str, default=None, help='Path to image embeddings file.')
    parser.add_argument('--decoder_layers', type=int, default=None, help='Override decoder layers count for architecture experiments.')
    args = parser.parse_args()

    config = get_config()

    if args.disable_behavior_expert: config['expert_system']['experts']['behavior_expert'] = False
    if args.disable_content_expert: config['expert_system']['experts']['content_expert'] = False
    if args.disable_image_expert: config['expert_system']['experts']['image_expert'] = False
    if args.enable_image_expert: config['expert_system']['experts']['image_expert'] = True
    
    # Override decoder layers if specified
    if args.decoder_layers is not None:
        config['decoder_model']['num_layers'] = args.decoder_layers
        logging.info(f"Overriding decoder layers to: {args.decoder_layers}")

    # 2. ç¯å¢ƒè®¾ç½®
    device = torch.device(config['device'])
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True
        torch.cuda.empty_cache()
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
    random.seed(config['seed'])
    np.random.seed(config['seed'])
    torch.manual_seed(config['seed'])
    if torch.cuda.is_available(): torch.cuda.manual_seed_all(config['seed'])

    # 3. æ—¥å¿—è®¾ç½®
    log_dir_path = pathlib.Path(config['data']['log_dir'])
    log_dir_path.mkdir(parents=True, exist_ok=True)
    log_file = log_dir_path / 'train_genius_rec.log'
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.FileHandler(log_file), logging.StreamHandler()])
    logging.info("=== Starting GENIUS-Rec Training ===")
    logging.info(f"Device: {device}")
    logging.info(f"Arguments: {args}")

     # 4. æ•°æ®åŠ è½½å’ŒIDæ˜ å°„å¤„ç†
    logging.info("Loading data from processed directory...")
    with open(config['data']['id_maps_file'], 'rb') as f:
        id_maps = pickle.load(f)
    num_special_tokens = id_maps.get('num_special_tokens', 4)
    total_vocab_size = id_maps['num_items'] + num_special_tokens
    config['encoder_model']['item_num'] = total_vocab_size
    config['decoder_model']['num_items'] = total_vocab_size
    num_items = total_vocab_size
    logging.info(f"Vocabulary Size: {total_vocab_size}")
    enabled_experts = [k for k, v in config['expert_system']['experts'].items() if v]
    if not enabled_experts: raise ValueError("At least one expert must be enabled!")
    logging.info(f"Enabled experts: {enabled_experts}")

    # ã€æ ¸å¿ƒä¿®æ”¹ã€‘åˆ›å»ºDatasetæ—¶ä¼ å…¥id_maps
    train_dataset = Seq2SeqRecDataset(config, config['data']['train_file'], is_validation=False, item_maps=id_maps)
    val_dataset = Seq2SeqRecDataset(config, config['data']['validation_file'], is_validation=True, item_maps=id_maps)
    test_dataset = ValidationDataset(config['data']['test_file'], config['encoder_model']['max_len'], config['pad_token_id'])
    
    train_loader = DataLoader(train_dataset, batch_size=config['finetune']['batch_size'], shuffle=True, num_workers=config['finetune']['num_workers'], pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=config['finetune']['batch_size'], shuffle=False, num_workers=config['finetune']['num_workers'], pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=config['finetune']['batch_size'], shuffle=False, num_workers=config['finetune']['num_workers'], pin_memory=True)
    pad_token_id = config['pad_token_id']
    top_k = config['evaluation']['top_k']
    logging.info(f"Dataset Info: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}")


    # 5. æ–‡æœ¬åµŒå…¥åŠ è½½
    logging.info("Loading pre-computed and filtered text embeddings...")
    text_embedding_file = config['data']['data_dir'] / 'book_gemini_embeddings_filtered_migrated.npy'
    try:
        text_embeddings_dict = np.load(text_embedding_file, allow_pickle=True).item()
    except FileNotFoundError:
        logging.error(f"Filtered embedding file not found at '{text_embedding_file}'! Please run filter_embeddings.py first.")
        return

    text_embedding_dim = next(iter(text_embeddings_dict.values())).shape[0]
    text_embedding_matrix = torch.zeros(total_vocab_size, text_embedding_dim, dtype=torch.float)
    
    item_asin_map = id_maps['item_map']
    loaded_count = 0
    for asin, embedding in text_embeddings_dict.items():
        if asin in item_asin_map:
            item_id = item_asin_map[asin]
            text_embedding_matrix[item_id] = torch.tensor(embedding, dtype=torch.float)
            loaded_count += 1
    
    logging.info(f"Successfully loaded and mapped {loaded_count} text embeddings.")
    if loaded_count == 0:
        logging.warning("No embeddings were mapped. The content expert will not function.")

    # 6. æ¨¡å‹åˆå§‹åŒ–ï¼ˆä½¿ç”¨é…ç½®å­—å…¸ï¼‰
    config['decoder_model']['text_embedding_dim'] = text_embedding_dim
    
    # ã€æ–°å¢ã€‘ä¼ é€’ä¸“å®¶é…ç½®åˆ°æ¨¡å‹
    model = GENIUSRecModel(config).to(device)
    logging.info("GENIUS-Rec model created with expert configuration.")
    
    # æ‰“å°å¯ç”¨çš„ä¸“å®¶ä¿¡æ¯
    enabled_experts = [k for k, v in config['expert_system']['experts'].items() if v]
    logging.info(f"ğŸ§  å¯ç”¨çš„ä¸“å®¶: {enabled_experts}")
    
    # æ˜¾å­˜ä½¿ç”¨æŠ¥å‘Š
    if torch.cuda.is_available():
        memory_allocated = torch.cuda.memory_allocated() / 1024**3
        memory_reserved = torch.cuda.memory_reserved() / 1024**3
        memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logging.info(f"ğŸ’¾ GPUæ˜¾å­˜çŠ¶æ€:")
        logging.info(f"   - å·²åˆ†é…: {memory_allocated:.2f}GB")
        logging.info(f"   - å·²é¢„ç•™: {memory_reserved:.2f}GB") 
        logging.info(f"   - æ€»å®¹é‡: {memory_total:.2f}GB")
        logging.info(f"   - å‰©ä½™å¯ç”¨: {memory_total - memory_reserved:.2f}GB")
    
   # 7. æ–­ç‚¹ç»­ä¼ ä¸é¢„è®­ç»ƒæƒé‡åŠ è½½çš„é€»è¾‘ (æœ€ç»ˆä¿®å¤ç‰ˆ)
    # æ­¥éª¤ A: ä¼˜å…ˆå°è¯•ä»å®Œæ•´æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    start_epoch, best_val_loss, patience_counter = 0, float('inf'), 0
    resumed_from_checkpoint = False  # æ–°å¢ä¸€ä¸ªæ ‡å¿—ä½ï¼Œåˆ¤æ–­æ˜¯å¦æˆåŠŸä»æ£€æŸ¥ç‚¹æ¢å¤
    latest_model_path = config['data']['checkpoint_dir'] / 'genius_rec_moe_latest.pth'
    resume_path = args.resume_from or latest_model_path
    if os.path.exists(resume_path):
        logging.info(f"å‘ç°æ£€æŸ¥ç‚¹æ–‡ä»¶: {resume_path}ï¼Œå°è¯•æ¢å¤...")
        resume_info = load_checkpoint(resume_path, model, optimizer, scheduler, device)
        if resume_info:
            start_epoch = resume_info['epoch'] + 1
            best_val_loss = resume_info['best_val_loss']
            patience_counter = resume_info['patience_counter']
            resumed_from_checkpoint = True
            logging.info(f"âœ… æˆåŠŸä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ! å°†ä» Epoch {start_epoch} ç»§ç»­ã€‚")

    # æ­¥éª¤ B: ä»…åœ¨"å†·å¯åŠ¨"ï¼ˆå³æ²¡æœ‰ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼‰æ—¶ï¼Œæ‰åŠ è½½ç‹¬ç«‹çš„é¢„è®­ç»ƒç¼–ç å™¨æƒé‡
    if not resumed_from_checkpoint and args.encoder_weights_path:
        logging.info(f"â–¶ï¸ å†·å¯åŠ¨æ¨¡å¼ï¼šæ­£åœ¨ä» '{args.encoder_weights_path}' åŠ è½½é¢„è®­ç»ƒç¼–ç å™¨...")
        try:
            weights_path = Path(args.encoder_weights_path)
            checkpoint = torch.load(weights_path, map_location=device, weights_only=False)
            
            # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
            if 'model_state_dict' in checkpoint:
                encoder_state_dict = checkpoint['model_state_dict']
                logging.info("   - æ ¼å¼ 'model_state_dict' å·²è¯†åˆ«ã€‚")
            else:
                encoder_state_dict = checkpoint
                logging.info("   - ç›´æ¥å°†æ–‡ä»¶ä½œä¸º state_dict ä½¿ç”¨ã€‚")
            
            # å¤„ç†item_numä¸åŒ¹é…é—®é¢˜
            current_item_embedding_size = model.encoder.item_embedding.weight.shape
            checkpoint_item_embedding_size = encoder_state_dict.get('item_embedding.weight', torch.empty(0)).shape
            
            if checkpoint_item_embedding_size != current_item_embedding_size:
                logging.warning(f"   - ç‰©å“åµŒå…¥å±‚å°ºå¯¸ä¸åŒ¹é…:")
                logging.warning(f"     - å½“å‰æ¨¡å‹: {current_item_embedding_size}")
                logging.warning(f"     - æ£€æŸ¥ç‚¹: {checkpoint_item_embedding_size}")
                logging.info("   - æ­£åœ¨æ™ºèƒ½è°ƒæ•´å°ºå¯¸...")
                
                if len(checkpoint_item_embedding_size) > 0:
                    old_embedding = encoder_state_dict['item_embedding.weight']
                    new_embedding = model.encoder.item_embedding.weight.data.clone()
                    min_items = min(old_embedding.shape[0], new_embedding.shape[0])
                    new_embedding[:min_items] = old_embedding[:min_items]
                    encoder_state_dict['item_embedding.weight'] = new_embedding
                    logging.info(f"     - âœ… å·²æ‹·è´ {min_items} ä¸ªç‰©å“çš„åµŒå…¥ã€‚")
            
            missing_keys, unexpected_keys = model.encoder.load_state_dict(encoder_state_dict, strict=False)
            
            if missing_keys:
                logging.warning(f"   - åŠ è½½æ—¶å‘ç°ç¼ºå¤±çš„é”®: {missing_keys}")
            if unexpected_keys:
                logging.warning(f"   - åŠ è½½æ—¶å‘ç°æ„å¤–çš„é”®: {unexpected_keys}")
                
            logging.info("âœ… é¢„è®­ç»ƒ HSTU ç¼–ç å™¨æƒé‡åŠ è½½æˆåŠŸã€‚")
            
        except Exception as e:
            logging.error(f"âŒ åŠ è½½é¢„è®­ç»ƒç¼–ç å™¨æƒé‡å¤±è´¥: {e}")
            logging.info("   - å°†ä»é›¶å¼€å§‹è®­ç»ƒ...")
    elif resumed_from_checkpoint:
        logging.info("â˜‘ï¸ å·²ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼Œè·³è¿‡åŠ è½½ç‹¬ç«‹çš„HSTUç¼–ç å™¨æƒé‡ã€‚")

    # æ­¥éª¤ C: å†»ç»“ç¼–ç å™¨ï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
    # è¿™ä¸ªé€»è¾‘åœ¨æ‰€æœ‰æƒé‡åŠ è½½æ“ä½œä¹‹åæ‰§è¡Œï¼Œç¡®ä¿çŠ¶æ€æ­£ç¡®ã€‚
    if args.freeze_encoder:
        for param in model.encoder.parameters():
            param.requires_grad = False
        logging.info("ğŸ”’ ç¼–ç å™¨æƒé‡å·²å†»ç»“ï¼Œåœ¨è®­ç»ƒä¸­ä¸ä¼šæ›´æ–°ã€‚")

    # 8. æ–‡æœ¬åµŒå…¥åŠ è½½åˆ°æ¨¡å‹
    model.decoder.load_text_embeddings(text_embedding_matrix.to(device))
    
    # ã€æ–°å¢ã€‘æ™ºèƒ½å›¾åƒåµŒå…¥åŠ è½½ç³»ç»Ÿ ğŸ¨
    if config['expert_system']['experts']['image_expert']:
        image_embeddings_path = args.image_embeddings_path or "data/book_image_embeddings_migrated.npy"
        
        if os.path.exists(image_embeddings_path):
            logging.info(f"ğŸ¨ Loading visual expert embeddings from: {image_embeddings_path}")
            try:
                # åŠ è½½å›¾åƒåµŒå…¥å­—å…¸
                image_embeddings_dict = np.load(image_embeddings_path, allow_pickle=True).item()
                
                if isinstance(image_embeddings_dict, dict) and len(image_embeddings_dict) > 0:
                    # è·å–åµŒå…¥ç»´åº¦
                    sample_embedding = next(iter(image_embeddings_dict.values()))
                    image_embedding_dim = sample_embedding.shape[0]
                    logging.info(f"ğŸ“ Image embedding dimension: {image_embedding_dim}")
                    
                    # ğŸ”§ ä¿®å¤ï¼šæ›´æ–°é…ç½®ä½†ä¸é‡æ–°åˆå§‹åŒ–æ•´ä¸ªæ¨¡å‹
                    config['expert_system']['image_expert']['image_embedding_dim'] = image_embedding_dim
                    
                    # ğŸ”§ ä¿®å¤ï¼šä»é…ç½®ä¸­è·å–å½“å‰ç»´åº¦ï¼Œè€Œä¸æ˜¯ä»å ä½ç¬¦çŸ©é˜µ
                    current_image_dim = config['expert_system']['image_expert'].get('image_embedding_dim', None)
                    
                    # åªæœ‰å½“é…ç½®ä¸­çš„ç»´åº¦ä¸å®é™…æ–‡ä»¶ç»´åº¦ä¸åŒ¹é…æ—¶æ‰é‡æ–°åˆå§‹åŒ–
                    if current_image_dim != image_embedding_dim:
                        logging.warning(f"å›¾åƒåµŒå…¥ç»´åº¦ä¸åŒ¹é…: é…ç½®={current_image_dim}, æ–‡ä»¶={image_embedding_dim}")
                        logging.info("éœ€è¦é‡æ–°åˆå§‹åŒ–æ¨¡å‹ä»¥é€‚é…å›¾åƒåµŒå…¥ç»´åº¦...")
                        
                        # é‡æ–°åˆå§‹åŒ–æ¨¡å‹
                        model = GENIUSRecModel(config).to(device)
                        
                        # é‡æ–°åŠ è½½ç¼–ç å™¨æƒé‡
                        if args.encoder_weights_path:
                            try:
                                logging.info("ğŸ”„ é‡æ–°åŠ è½½ç¼–ç å™¨æƒé‡...")
                                checkpoint = torch.load(args.encoder_weights_path, map_location=device, weights_only=False)
                                encoder_state_dict = checkpoint.get('model_state_dict', checkpoint)
                                
                                # å¤„ç†item_numä¸åŒ¹é…
                                current_item_embedding_size = model.encoder.item_embedding.weight.shape
                                checkpoint_item_embedding_size = encoder_state_dict.get('item_embedding.weight', torch.empty(0)).shape
                                
                                if checkpoint_item_embedding_size != current_item_embedding_size:
                                    if len(checkpoint_item_embedding_size) > 0:
                                        old_embedding = encoder_state_dict['item_embedding.weight']
                                        new_embedding = model.encoder.item_embedding.weight.data.clone()
                                        min_items = min(old_embedding.shape[0], new_embedding.shape[0])
                                        new_embedding[:min_items] = old_embedding[:min_items]
                                        encoder_state_dict['item_embedding.weight'] = new_embedding
                                
                                model.encoder.load_state_dict(encoder_state_dict, strict=False)
                                
                                if args.freeze_encoder:
                                    for param in model.encoder.parameters():
                                        param.requires_grad = False
                                        
                                # é‡æ–°åŠ è½½æ–‡æœ¬åµŒå…¥ï¼ˆé™é»˜æ¨¡å¼ï¼Œé¿å…é‡å¤æ—¥å¿—ï¼‰
                                model.decoder.load_text_embeddings(text_embedding_matrix.to(device), verbose=False)
                                
                            except Exception as e:
                                logging.error(f"é‡æ–°åŠ è½½ç¼–ç å™¨æƒé‡å¤±è´¥: {e}")
                    
                    # åˆå§‹åŒ–å›¾åƒåµŒå…¥çŸ©é˜µ
                    num_items = total_vocab_size  # ä½¿ç”¨æ€»è¯æ±‡è¡¨å¤§å°
                    image_embedding_matrix = torch.randn(num_items, image_embedding_dim, dtype=torch.float) * 0.01
                    
                    # æ˜ å°„item_idå¹¶åŠ è½½åµŒå…¥ - ç°åœ¨ç»Ÿä¸€ä½¿ç”¨item_idä½œä¸ºé”®
                    loaded_image_count = 0
                    
                    for item_id, embedding in image_embeddings_dict.items():
                        # æ‰€æœ‰é”®ç°åœ¨éƒ½æ˜¯item_id (æ•´æ•°)
                        if isinstance(item_id, (int, np.int32, np.int64)) and 0 <= item_id < num_items:
                            image_embedding_matrix[item_id] = torch.tensor(embedding, dtype=torch.float)
                            loaded_image_count += 1
                    
                    # åŠ è½½åˆ°æ¨¡å‹
                    model.decoder.load_image_embeddings(image_embedding_matrix.to(device))
                    
                    # ç»Ÿè®¡ä¿¡æ¯
                    coverage_rate = (loaded_image_count / num_items) * 100
                    logging.info(f"âœ… Visual Expert Integration Complete!")
                    logging.info(f"   ğŸ“Š Loaded {loaded_image_count:,} image embeddings (item_id keys)")
                    logging.info(f"   ğŸ“ˆ Coverage: {coverage_rate:.1f}% of {num_items:,} items")
                    
                    if coverage_rate < 50:
                        logging.warning(f"âš ï¸  Low image coverage ({coverage_rate:.1f}%). Consider generating more image embeddings.")
                    
                else:
                    raise ValueError("Empty or invalid image embeddings dictionary")
                    
            except Exception as e:
                logging.error(f"âŒ Failed to load image embeddings: {e}")
                logging.info("ğŸ”„ Gracefully disabling visual expert...")
                config['expert_system']['experts']['image_expert'] = False
        else:
            logging.warning(f"ğŸ“ Image embeddings file not found: {image_embeddings_path}")
            logging.info("ğŸ’¡ To enable visual expert, generate image embeddings first:")
            logging.info(f"   python generate_image_embeddings.py --input_dir data/book_covers_enhanced --output_file {image_embeddings_path}")
            logging.info("ğŸ”„ Disabling visual expert for this run...")
            config['expert_system']['experts']['image_expert'] = False

    # ğŸš€ æ˜¾å­˜ä¼˜åŒ–ï¼šå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
    try:
        scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else None
    except AttributeError:
        # å…¼å®¹æ—§ç‰ˆæœ¬PyTorch
        scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None
    

    # --- å‚æ•°åˆ†ç»„ (Parameter Grouping) ---
    
    # ç»„1ï¼šé—¨æ§ç½‘ç»œå‚æ•°
    gate_params = [p for n, p in model.named_parameters() if 'gate_network' in n and p.requires_grad]
    
    # ã€æ–°å¢ã€‘ç»„2ï¼šä¸“å®¶æŠ•å½±å±‚å‚æ•° (æˆ‘ä»¬å¸Œæœ›å®ƒä»¬å¿«é€Ÿå­¦ä¹ )
    expert_projection_params = [
        p for n, p in model.named_parameters() 
        if ('content_expert_projection' in n or 'image_expert_projection' in n) and p.requires_grad
    ]
    
    # ç»„3ï¼šç¼–ç å™¨ä¸­ *é™¤äº†* item_embedding ä¹‹å¤–çš„æ‰€æœ‰å‚æ•° (å¾®è°ƒ)
    encoder_other_params = [p for n, p in model.encoder.named_parameters() if 'item_embedding' not in n and p.requires_grad]
    
    # ç»„4ï¼šå…±äº«çš„ item_embedding å‚æ•° (éœ€è¦è¾ƒé«˜å­¦ä¹ ç‡)
    item_embedding_params = [p for n, p in model.encoder.named_parameters() if 'item_embedding' in n and p.requires_grad]
    
    # ç»„5ï¼šè§£ç å™¨ä¸»å¹²å‚æ•° (å…¶ä»–æ‰€æœ‰å‚æ•°)
    grouped_param_ids = {
        id(p) for p_group in [gate_params, expert_projection_params, encoder_other_params, item_embedding_params] 
        for p in p_group
    }
    decoder_main_params = [p for n, p in model.named_parameters() if id(p) not in grouped_param_ids and p.requires_grad]

    # ä»é…ç½®ä¸­è·å–å­¦ä¹ ç‡
    decoder_lr = config['finetune']['learning_rate'].get('decoder_lr', 1e-4)
    embedding_lr = config['finetune']['learning_rate'].get('embedding_lr', decoder_lr) 
    gate_lr = config['finetune']['learning_rate'].get('gate_lr', 1e-4)
    encoder_lr = config['finetune']['learning_rate'].get('encoder_lr', 5e-6)
    # ã€æ–°å¢ã€‘ä¸ºä¸“å®¶æŠ•å½±å±‚è®¾ç½®ä¸€ä¸ªæ›´é«˜çš„å­¦ä¹ ç‡
    # è­¦å‘Šï¼šåŸå§‹é…ç½®ä¸­çš„å­¦ä¹ ç‡å¯èƒ½è¿‡é«˜ï¼Œå¯¼è‡´æ¨¡å‹å‘æ•£ã€‚æ­¤å¤„å¼ºåˆ¶ä½¿ç”¨æ›´å®‰å…¨çš„å€¼ã€‚
    expert_projection_lr = config['finetune']['learning_rate'].get('expert_projection_lr', 1e-4)

    # åˆ›å»ºæœ€ç»ˆç‰ˆçš„ä¼˜åŒ–å™¨å®ä¾‹
    optimizer = torch.optim.AdamW([
        {'params': decoder_main_params, 'lr': decoder_lr},
        {'params': item_embedding_params, 'lr': embedding_lr, 'weight_decay': 0},
        {'params': gate_params, 'lr': gate_lr},
        {'params': encoder_other_params, 'lr': encoder_lr},
        {'params': expert_projection_params, 'lr': expert_projection_lr} # ğŸ‘ˆ æ–°å¢å‚æ•°ç»„
    ], weight_decay=config['finetune']['weight_decay'])

    # æ‰“å°æ—¥å¿—ä»¥ç¡®è®¤è®¾ç½®
    logging.info(f"  - è§£ç å™¨ä¸»å¹²å­¦ä¹ ç‡: {decoder_lr}")
    logging.info(f"  - å…±äº«åµŒå…¥å±‚å­¦ä¹ ç‡: {embedding_lr}")
    logging.info(f"  - é—¨æ§ç½‘ç»œå­¦ä¹ ç‡: {gate_lr}")
    logging.info(f"  - ä¸“å®¶æŠ•å½±å±‚å­¦ä¹ ç‡: {expert_projection_lr}")
    logging.info(f"  - ç¼–ç å™¨å…¶ä»–éƒ¨åˆ†å­¦ä¹ ç‡: {encoder_lr}")

    # æŸå¤±å‡½æ•°å®šä¹‰ (ä¿æŒä¸å˜)
    criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id, label_smoothing=config['finetune'].get('label_smoothing', 0))
    # 10. å­¦ä¹ ç‡è°ƒåº¦å™¨
    num_training_steps = len(train_loader) * config['finetune']['num_epochs']
    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=config['finetune']['warmup_steps'], num_training_steps=num_training_steps)
    
    # 11. æ£€æŸ¥ç‚¹ç›®å½•å’Œæ··åˆç²¾åº¦
    output_dir = pathlib.Path(args.save_dir or config['data']['checkpoint_dir'])
    output_dir.mkdir(parents=True, exist_ok=True)
    best_model_path = output_dir / 'genius_rec_best.pth'
    latest_model_path = output_dir / 'genius_rec_latest.pth'
    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None

    # 12. æ–­ç‚¹ç»­ä¼ 
    start_epoch, best_val_loss, patience_counter = 0, float('inf'), 0
    resume_path = args.resume_from or latest_model_path
    if os.path.exists(resume_path):
        resume_info = load_checkpoint(resume_path, model, optimizer, scheduler, device)
        if resume_info:
            start_epoch = resume_info['epoch'] + 1
            best_val_loss = resume_info['best_val_loss']
            patience_counter = resume_info['patience_counter']
            logging.info(f"âœ… æˆåŠŸæ¢å¤è®­ç»ƒçŠ¶æ€! ä» Epoch {start_epoch} ç»§ç»­ (Best Val Loss: {best_val_loss:.4f})")




    # 13. è®­ç»ƒä¸»å¾ªç¯ (æœ€ç»ˆç‰ˆ)
    logging.info("=== Starting Training Loop ===")
    for epoch in range(start_epoch, config['finetune']['num_epochs']):
        avg_train_loss = train_one_epoch(
            model, train_loader, criterion, optimizer, scheduler, device, epoch,
            config['finetune']['num_epochs'], pad_token_id, config, scaler
        )
        

        eval_results = evaluate_model_validation_with_ranking(
            model, val_loader, criterion, device,
            epoch, config['finetune']['num_epochs'], pad_token_id,
            config=config, top_k=top_k
        )
        
        current_val_loss = eval_results['val_loss']
        is_best = current_val_loss < best_val_loss

        if is_best:
            best_val_loss = current_val_loss
            patience_counter = 0
            logging.info(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³æ¨¡å‹! Val Loss: {best_val_loss:.4f}")
        else:
            patience_counter += 1
        
        checkpoint_metrics = {'best_val_loss': best_val_loss, 'patience_counter': patience_counter, **eval_results}
        
        if is_best:
            save_checkpoint(best_model_path, model, optimizer, scheduler, epoch, checkpoint_metrics, config, num_items)
            logging.info(f"å·²ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°: {best_model_path}")
        
        save_checkpoint(latest_model_path, model, optimizer, scheduler, epoch, checkpoint_metrics, config, num_items)
        logging.info(f"å·²ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹åˆ°: {latest_model_path}")

        logging.info(f"Epoch {epoch+1}/{config['finetune']['num_epochs']} Results:")
        logging.info(f"  ğŸ“ˆ Train Loss: {avg_train_loss:.4f}")
        logging.info(f"  ğŸ“‰ Val Loss: {current_val_loss:.4f} (Best: {best_val_loss:.4f})")
        logging.info(f"  ğŸ“Š Val PPL: {eval_results['val_ppl']:.4f}")
        logging.info(f"  ğŸ¯ Val HR@{top_k}: {eval_results['val_hr']:.4f}")
        logging.info(f"  ğŸ¯ Val NDCG@{top_k}: {eval_results['val_ndcg']:.4f}")
        
        for expert_name in enabled_experts:
            weight_key = f'avg_{expert_name}_weight'
            if weight_key in eval_results and eval_results[weight_key] is not None:
                logging.info(f"  âš–ï¸  {expert_name.replace('_', ' ').title()} Weight: {eval_results[weight_key]:.4f}")

        early_stopping_patience = config['finetune'].get('early_stopping_patience', 10)
        logging.info(f"è€å¿ƒè®¡æ•°: {patience_counter}/{early_stopping_patience}")
        if patience_counter >= early_stopping_patience:
            logging.info(f"è§¦å‘æ—©åœ! è¿ç»­ {patience_counter} ä¸ªepochæ€§èƒ½æœªæå‡")
            break
            
        logging.info("-" * 80)

    # 14. æœ€ç»ˆæµ‹è¯•è¯„ä¼°
    logging.info("=== Final Test Evaluation ===")
    if os.path.exists(best_model_path):
        logging.info(f"åŠ è½½æœ€ä½³æ¨¡å‹ {best_model_path} è¿›è¡Œæµ‹è¯•...")
        checkpoint = torch.load(best_model_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        
        test_results = evaluate_model_test(model, test_loader, device, num_items, top_k=top_k, config=config)
        
        logging.info(f"ğŸ“ˆ Final Test Results:")
        logging.info(f"  ğŸ¯ Test HR@{top_k}: {test_results['test_hr']:.4f}")
        logging.info(f"  ğŸ¯ Test NDCG@{top_k}: {test_results['test_ndcg']:.4f}")
    else:
        logging.warning("æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶ï¼Œè·³è¿‡æµ‹è¯•é›†è¯„ä¼°ã€‚")

if __name__ == '__main__':
    main()