import argparse
import logging
import os
import pickle
import random
import math
from tqdm import tqdm
import pathlib
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset

# è®­ç»ƒå‚æ•°
# å†»ç»“ç¼–ç å™¨å‚æ•°ï¼Œé˜²æ­¢å…¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­è¢«æ›´æ–°
# python -m src.train_GeniusRec --encoder_weights_path checkpoints/hstu_encoder.pth --freeze_encoder
# ä¸ä½¿ç”¨å†»ç»“ç¼–ç å™¨å‚æ•°
# python -m src.train_GeniusRec --encoder_weights_path checkpoints/hstu_encoder.pth

from src.config import get_config
from src.GeniusRec import GENIUSRecModel
from src.dataset import Seq2SeqRecDataset
import platform


# --- 1. è®­ç»ƒå’Œè¯„ä¼°å‡½æ•° ---
def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch, num_epochs):
    model.train()
    total_loss = 0.0
    progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs} [Training]")

    for batch in progress_bar:
        source_ids = batch['source_ids'].to(device)
        decoder_input_ids = batch['decoder_input_ids'].to(device)
        labels = batch['labels'].to(device)
        source_padding_mask = (source_ids == 0).to(device)
        optimizer.zero_grad()
        
        # æ¨¡å‹å‰å‘ä¼ æ’­
        logits = model(source_ids, decoder_input_ids, source_padding_mask)

        # è®¡ç®—æŸå¤±
        # logits: (B, target_len, num_items) -> (B * target_len, num_items)
        # labels: (B, target_len) -> (B * target_len)
        loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))
        
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # æ¢¯åº¦è£å‰ª
        optimizer.step()
        
        total_loss += loss.item()
        progress_bar.set_postfix(loss=loss.item(), avg_loss=total_loss/len(progress_bar))
        
    return total_loss / len(dataloader)

def evaluate(model, dataloader, criterion, device, epoch, num_epochs):
    model.eval()
    total_loss = 0.0
    progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs} [Validation]")

    with torch.no_grad():
        for batch in progress_bar:
            source_ids = batch['source_ids'].to(device)
            decoder_input_ids = batch['decoder_input_ids'].to(device)
            labels = batch['labels'].to(device)
            source_padding_mask = (source_ids == 0).to(device)

            logits = model(source_ids, decoder_input_ids, source_padding_mask)
            loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))
            
            total_loss += loss.item()
            progress_bar.set_postfix(loss=loss.item(), avg_loss=total_loss/len(progress_bar))

    avg_loss = total_loss / len(dataloader)
    perplexity = math.exp(avg_loss) # å›°æƒ‘åº¦æ˜¯è¯„ä¼°ç”Ÿæˆæ¨¡å‹å¸¸ç”¨æŒ‡æ ‡
    return avg_loss, perplexity


# --- 2. ä¸»å‡½æ•° ---
def main():
    parser = argparse.ArgumentParser(description="Fine-tuning script for GENIUS-Rec model.")
    parser.add_argument('--config_path', type=str, help='Path to your project config file (optional).')
    parser.add_argument('--encoder_weights_path', type=str, required=True, help='Path to pre-trained HSTU encoder weights.')
    parser.add_argument('--freeze_encoder', action='store_true', help='Freeze encoder weights during fine-tuning.')
    parser.add_argument('--save_dir', type=str, default='checkpoints/checkpoints_genius_rec', help='Directory to save fine-tuned models.')
    args = parser.parse_args()

    # --- åˆå§‹åŒ– ---
    config = get_config() # ä½¿ç”¨æ‚¨æä¾›çš„config.py
    device = torch.device(config['device'])
    random.seed(config['seed'])
    np.random.seed(config['seed'])
    torch.manual_seed(config['seed'])
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(config['seed'])

    os.makedirs(args.save_dir, exist_ok=True)
    # ç¡®ä¿ config['data']['log_dir'] æ˜¯ pathlib.Path å¯¹è±¡
    log_dir_path = config['data']['log_dir']
    if not isinstance(log_dir_path, pathlib.Path):
        from pathlib import Path
        log_dir_path = Path(log_dir_path)

    log_dir_path.mkdir(parents=True, exist_ok=True)
    log_file = log_dir_path / config['finetune']['log_file']
    logging.basicConfig(level=logging.INFO,
                        format='%(asctime)s - %(levelname)s - %(message)s',
                        handlers=[logging.FileHandler(log_file), logging.StreamHandler()])

    logging.info("--- Starting GENIUS-Rec Fine-tuning ---")
    logging.info(f"Device: {device}")
    logging.info(f"Arguments: {args}")

    # --- å‡†å¤‡æ•°æ® ---
    with open(config['data']['id_maps_file'], 'rb') as f:
        id_maps = pickle.load(f)
        num_items = id_maps['num_items'] + 1 # +1 for padding token
    
    train_dataset = Seq2SeqRecDataset(config['data']['train_file'], config['decoder_model']['max_seq_len'], split_ratio=config['finetune']['split_ratio'])
    val_dataset = Seq2SeqRecDataset(config['data']['validation_file'], config['decoder_model']['max_seq_len'], split_ratio=config['finetune']['split_ratio'])
    train_loader = DataLoader(train_dataset, batch_size=config['finetune']['batch_size'], shuffle=True, num_workers=config['finetune']['num_workers'])
    val_loader = DataLoader(val_dataset, batch_size=config['finetune']['batch_size'], shuffle=False, num_workers=config['finetune']['num_workers'])
    logging.info(f"Data loaded. Training set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}")

    # --- æ„å»ºæ¨¡å‹ ---
    # æ„å»ºencoderé…ç½®
    encoder_config = {
        'item_num': num_items,
        'embedding_dim': config['encoder_model']['embedding_dim'],
        'linear_hidden_dim': config['encoder_model']['linear_hidden_dim'],
        'attention_dim': config['encoder_model']['attention_dim'],
        'num_heads': config['encoder_model']['num_heads'],
        'num_layers': config['encoder_model']['num_layers'],
        'max_len': config['encoder_model']['max_len'],
        'dropout': config['encoder_model']['dropout'],
        'pad_token_id': config['pad_token_id']
    }
    # æ„å»ºdecoderé…ç½®
    decoder_config = {
        'num_items': num_items,
        'embedding_dim': config['decoder_model']['embedding_dim'],
        'num_layers': config['decoder_model']['num_layers'],
        'num_heads': config['decoder_model']['num_heads'],
        'ffn_hidden_dim': config['decoder_model']['ffn_hidden_dim'],
        'max_seq_len': config['decoder_model']['max_seq_len'],
        'dropout_ratio': config['decoder_model']['dropout_ratio']
    }
    model = GENIUSRecModel(encoder_config=encoder_config, decoder_config=decoder_config).to(device)
    logging.info("GENIUS-Rec model created.")

    # --- åŠ è½½é¢„è®­ç»ƒæƒé‡ ---
    logging.info(f"Loading pre-trained encoder weights from: {args.encoder_weights_path}")
    
  
    # å¦‚æœå½“å‰ç³»ç»Ÿæ˜¯Linuxï¼Œå¹¶ä¸”è¦åŠ è½½çš„æ–‡ä»¶å­˜åœ¨
    if platform.system() == "Linux" and os.path.exists(args.encoder_weights_path):
        # æš‚æ—¶å°† WindowsPath æŒ‡å‘ PosixPathï¼Œæ¬ºéª— unpickler
        temp_windows_path = pathlib.WindowsPath
        pathlib.WindowsPath = pathlib.PosixPath
    # +++ ç»“æŸä¿®æ”¹ +++

    # åŠ è½½çŠ¶æ€å­—å…¸ (è¿™è¡Œä»£ç æœ¬èº«ä¸å˜)
    encoder_state_dict = torch.load(args.encoder_weights_path, map_location=device)
    
    # +++ å¼€å§‹ä¿®æ”¹: æ¢å¤pathlibè®¾ç½® +++
    # åŠ è½½å®Œæˆåï¼Œæ¢å¤åŸå§‹çš„ pathlib.WindowsPathï¼Œé¿å…å½±å“åç»­æ“ä½œ
    if platform.system() == "Linux":
        pathlib.WindowsPath = temp_windows_path
    # +++ ç»“æŸä¿®æ”¹ +++
    
    # ä¸ºäº†å®‰å…¨ï¼ŒåªåŠ è½½é”®åŒ¹é…çš„æƒé‡
    model.encoder.load_state_dict(encoder_state_dict, strict=False) 
    logging.info("Encoder weights loaded successfully.")
    
    # --- å†»ç»“ä¸ä¼˜åŒ–å™¨è®¾ç½® ---
    if args.freeze_encoder:
        logging.info("Freezing encoder parameters.")
        for param in model.encoder.parameters():
            param.requires_grad = False
        optimizer = torch.optim.AdamW(model.decoder.parameters(), lr=config['finetune']['learning_rate']['decoder_lr'], weight_decay=config['finetune']['weight_decay'])
    else:
        logging.info("Fine-tuning both encoder and decoder with different learning rates.")
        optimizer = torch.optim.AdamW([
            {'params': model.decoder.parameters(), 'lr': config['finetune']['learning_rate']['decoder_lr']},
            {'params': model.encoder.parameters(), 'lr': config['finetune']['learning_rate']['encoder_lr']}
        ], weight_decay=config['finetune']['weight_decay'])
        
    criterion = nn.CrossEntropyLoss(ignore_index=config['pad_token_id'])
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, verbose=True)

    # --- æ–­ç‚¹ç»­ä¼ é€»è¾‘ ---
    start_epoch = 0
    best_perplexity = float('inf')
    patience_counter = 0
    
    # æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
    latest_ckpt_path = os.path.join(args.save_dir, 'genius_rec_latest.pth')
    best_ckpt_path = os.path.join(args.save_dir, 'genius_rec_best.pth')
    
    # å°è¯•åŠ è½½æœ€æ–°æ£€æŸ¥ç‚¹è¿›è¡Œæ–­ç‚¹ç»­ä¼ 
    if os.path.exists(latest_ckpt_path):
        logging.info(f"å‘ç°æœ€æ–°æ£€æŸ¥ç‚¹: {latest_ckpt_path}ï¼Œæ­£åœ¨åŠ è½½...")
        try:
            checkpoint = torch.load(latest_ckpt_path, map_location=device)
            
            # åŠ è½½æ¨¡å‹çŠ¶æ€
            model.load_state_dict(checkpoint['model_state_dict'])
            
            # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            
            # åŠ è½½è°ƒåº¦å™¨çŠ¶æ€
            if 'scheduler_state_dict' in checkpoint:
                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            
            # æ¢å¤è®­ç»ƒçŠ¶æ€
            start_epoch = checkpoint['epoch'] + 1
            best_perplexity = checkpoint.get('best_perplexity', float('inf'))
            patience_counter = checkpoint.get('patience_counter', 0)
            
            logging.info(f"æˆåŠŸåŠ è½½æ£€æŸ¥ç‚¹! ä» Epoch {start_epoch} ç»§ç»­è®­ç»ƒ")
            logging.info(f"å½“å‰æœ€ä½³å›°æƒ‘åº¦: {best_perplexity:.4f}")
            logging.info(f"å½“å‰è€å¿ƒè®¡æ•°: {patience_counter}")
            
        except Exception as e:
            logging.warning(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            logging.info("å°†ä»å¤´å¼€å§‹è®­ç»ƒ")
            start_epoch = 0
            best_perplexity = float('inf')
            patience_counter = 0
    else:
        logging.info("æœªå‘ç°æ£€æŸ¥ç‚¹ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")

    # --- è®­ç»ƒå¾ªç¯ ---
    for epoch in range(start_epoch, config['finetune']['num_epochs']):
        avg_train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, config['finetune']['num_epochs'])
        avg_val_loss, perplexity = evaluate(model, val_loader, criterion, device, epoch, config['finetune']['num_epochs'])
        
        logging.info(f"Epoch {epoch+1}/{config['finetune']['num_epochs']} - Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Perplexity: {perplexity:.4f}")
        
        scheduler.step(avg_val_loss)
        
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹ï¼ˆæ¯ä¸ªepochéƒ½ä¿å­˜ï¼‰
        latest_checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'best_perplexity': best_perplexity,
            'current_perplexity': perplexity,
            'patience_counter': patience_counter,
            'train_loss': avg_train_loss,
            'val_loss': avg_val_loss,
            'config': config,
            'args': vars(args)
        }
        torch.save(latest_checkpoint, latest_ckpt_path)
        logging.info(f"æœ€æ–°æ£€æŸ¥ç‚¹å·²ä¿å­˜: {latest_ckpt_path}")
        
        # ä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹ï¼ˆä»…åœ¨æ€§èƒ½æå‡æ—¶ä¿å­˜ï¼‰
        if perplexity < best_perplexity:
            best_perplexity = perplexity
            patience_counter = 0
            
            best_checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'best_perplexity': best_perplexity,
                'current_perplexity': perplexity,
                'patience_counter': patience_counter,
                'train_loss': avg_train_loss,
                'val_loss': avg_val_loss,
                'config': config,
                'args': vars(args)
            }
            torch.save(best_checkpoint, best_ckpt_path)
            logging.info(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³æ¨¡å‹! å›°æƒ‘åº¦: {best_perplexity:.4f}")
            logging.info(f"æœ€ä½³æ£€æŸ¥ç‚¹å·²ä¿å­˜: {best_ckpt_path}")
        else:
            patience_counter += 1
            logging.info(f"æ€§èƒ½æœªæå‡ï¼Œè€å¿ƒè®¡æ•°: {patience_counter}/{config['finetune']['early_stopping_patience']}")
            if patience_counter >= config['finetune']['early_stopping_patience']:
                logging.info(f"è§¦å‘æ—©åœ! è¿ç»­ {patience_counter} ä¸ªepochæ€§èƒ½æœªæå‡")
                break
                
    logging.info("--- Fine-tuning finished ---")
    # å¦‚æœå¾ªç¯å› ä¸ºæ—©åœè€Œä¸­æ–­ï¼Œepochå¯èƒ½æ²¡æœ‰è¾¾åˆ°æœ€å¤§å€¼ï¼Œæ‰€ä»¥ç”¨ epoch+1
    completed_epochs = epoch + 1 if 'epoch' in locals() else start_epoch
    logging.info(f"è®­ç»ƒæ€»è½®æ¬¡: {completed_epochs}/{config['finetune']['num_epochs']}")
    logging.info(f"æœ€ä½³éªŒè¯å›°æƒ‘åº¦: {best_perplexity:.4f}")
    
    # æ˜¾ç¤ºæ£€æŸ¥ç‚¹ä¿¡æ¯
    if os.path.exists(best_ckpt_path):
        logging.info(f"âœ… æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹: {best_ckpt_path}")
    if os.path.exists(latest_ckpt_path):
        logging.info(f"âœ… æœ€æ–°æ¨¡å‹æ£€æŸ¥ç‚¹: {latest_ckpt_path}")

def load_checkpoint_info(checkpoint_path):
    """åŠ è½½å¹¶æ˜¾ç¤ºæ£€æŸ¥ç‚¹ä¿¡æ¯çš„è¾…åŠ©å‡½æ•°"""
    if not os.path.exists(checkpoint_path):
        return None
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        info = {
            'epoch': checkpoint.get('epoch', -1),
            'best_perplexity': checkpoint.get('best_perplexity', float('inf')),
            'current_perplexity': checkpoint.get('current_perplexity', float('inf')),
            'train_loss': checkpoint.get('train_loss', 0.0),
            'val_loss': checkpoint.get('val_loss', 0.0),
            'patience_counter': checkpoint.get('patience_counter', 0)
        }
        return info
    except Exception as e:
        print(f"åŠ è½½æ£€æŸ¥ç‚¹ä¿¡æ¯å¤±è´¥: {e}")
        return None

if __name__ == '__main__':
    main()