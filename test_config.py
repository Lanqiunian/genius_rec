#!/usr/bin/env python3
# test_config.py - æµ‹è¯•é‡æ„åçš„é…ç½®æ–‡ä»¶

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.config import get_config
import json

def test_config():
    """æµ‹è¯•é…ç½®æ–‡ä»¶æ˜¯å¦èƒ½æ­£å¸¸åŠ è½½å¹¶åŒ…å«æ‰€æœ‰å¿…è¦çš„é”®"""
    try:
        config = get_config()
        print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ!")
        
        # æ£€æŸ¥ä¸»è¦é…ç½®èŠ‚
        required_sections = ['data', 'encoder_model', 'decoder_model', 'pretrain', 'finetune', 'evaluation']
        for section in required_sections:
            if section in config:
                print(f"âœ… å‘ç°é…ç½®èŠ‚: {section}")
            else:
                print(f"âŒ ç¼ºå¤±é…ç½®èŠ‚: {section}")
                return False
        
        # æ£€æŸ¥æ•°æ®è·¯å¾„é…ç½®
        data_keys = ['data_dir', 'processed_data_dir', 'log_dir', 'checkpoint_dir', 
                     'train_file', 'validation_file', 'test_file', 'id_maps_file']
        for key in data_keys:
            if key in config['data']:
                print(f"âœ… æ•°æ®é…ç½®åŒ…å«: {key}")
            else:
                print(f"âŒ æ•°æ®é…ç½®ç¼ºå¤±: {key}")
                return False
        
        # æ£€æŸ¥ç¼–ç å™¨æ¨¡å‹é…ç½®
        encoder_keys = ['max_len', 'embedding_dim', 'linear_hidden_dim', 'attention_dim', 
                       'num_layers', 'num_heads', 'dropout']
        for key in encoder_keys:
            if key in config['encoder_model']:
                print(f"âœ… ç¼–ç å™¨é…ç½®åŒ…å«: {key}")
            else:
                print(f"âŒ ç¼–ç å™¨é…ç½®ç¼ºå¤±: {key}")
                return False
        
        # æ£€æŸ¥è§£ç å™¨æ¨¡å‹é…ç½®
        decoder_keys = ['max_seq_len', 'embedding_dim', 'num_layers', 'num_heads', 
                       'ffn_hidden_dim', 'dropout_ratio']
        for key in decoder_keys:
            if key in config['decoder_model']:
                print(f"âœ… è§£ç å™¨é…ç½®åŒ…å«: {key}")
            else:
                print(f"âŒ è§£ç å™¨é…ç½®ç¼ºå¤±: {key}")
                return False
        
        # æ£€æŸ¥é¢„è®­ç»ƒé…ç½®
        pretrain_keys = ['log_file', 'num_epochs', 'batch_size', 'learning_rate', 
                        'weight_decay', 'early_stopping_patience', 'num_workers', 
                        'num_neg_samples', 'temperature']
        for key in pretrain_keys:
            if key in config['pretrain']:
                print(f"âœ… é¢„è®­ç»ƒé…ç½®åŒ…å«: {key}")
            else:
                print(f"âŒ é¢„è®­ç»ƒé…ç½®ç¼ºå¤±: {key}")
                return False
        
        # æ£€æŸ¥å¾®è°ƒé…ç½®
        finetune_keys = ['log_file', 'num_epochs', 'batch_size', 'learning_rate', 
                        'weight_decay', 'early_stopping_patience', 'num_workers', 'split_ratio']
        for key in finetune_keys:
            if key in config['finetune']:
                print(f"âœ… å¾®è°ƒé…ç½®åŒ…å«: {key}")
            else:
                print(f"âŒ å¾®è°ƒé…ç½®ç¼ºå¤±: {key}")
                return False
        
        # æ£€æŸ¥å­¦ä¹ ç‡é…ç½®
        if 'decoder_lr' in config['finetune']['learning_rate'] and 'encoder_lr' in config['finetune']['learning_rate']:
            print("âœ… å¾®è°ƒå­¦ä¹ ç‡é…ç½®æ­£ç¡®")
        else:
            print("âŒ å¾®è°ƒå­¦ä¹ ç‡é…ç½®é”™è¯¯")
            return False
        
        # æ£€æŸ¥è¯„ä¼°é…ç½®
        if 'top_k' in config['evaluation']:
            print("âœ… è¯„ä¼°é…ç½®åŒ…å«: top_k")
        else:
            print("âŒ è¯„ä¼°é…ç½®ç¼ºå¤±: top_k")
            return False
        
        print("\nğŸ“‹ é…ç½®æ‘˜è¦:")
        print(f"è®¾å¤‡: {config['device']}")
        print(f"ç¼–ç å™¨åµŒå…¥ç»´åº¦: {config['encoder_model']['embedding_dim']}")
        print(f"ç¼–ç å™¨æœ€å¤§é•¿åº¦: {config['encoder_model']['max_len']}")
        print(f"è§£ç å™¨æœ€å¤§é•¿åº¦: {config['decoder_model']['max_seq_len']}")
        print(f"é¢„è®­ç»ƒè½®æ•°: {config['pretrain']['num_epochs']}")
        print(f"å¾®è°ƒè½®æ•°: {config['finetune']['num_epochs']}")
        print(f"é¢„è®­ç»ƒæ‰¹æ¬¡å¤§å°: {config['pretrain']['batch_size']}")
        print(f"å¾®è°ƒæ‰¹æ¬¡å¤§å°: {config['finetune']['batch_size']}")
        print(f"è¯„ä¼°Top-K: {config['evaluation']['top_k']}")
        
        print("\nâœ… é…ç½®é‡æ„æˆåŠŸ! æ‰€æœ‰å¿…è¦çš„é…ç½®éƒ½å·²æ­£ç¡®è®¾ç½®ã€‚")
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = test_config()
    if success:
        print("\nğŸ‰ é‡æ„å®Œæˆ! é…ç½®æ–‡ä»¶å·²æˆåŠŸé‡æ„ä¸ºæ–°çš„å±‚æ¬¡åŒ–ç»“æ„ã€‚")
        print("\nğŸ“ é‡æ„æ€»ç»“:")
        print("1. âœ… é…ç½®æ–‡ä»¶ç»“æ„å·²é‡ç»„ä¸ºå±‚æ¬¡åŒ–æ ¼å¼")
        print("2. âœ… ç¼–ç å™¨è®­ç»ƒè„šæœ¬é€‚é…å®Œæˆ")
        print("3. âœ… GeniusRecå¾®è°ƒè„šæœ¬é€‚é…å®Œæˆ") 
        print("4. âœ… Baselineè®­ç»ƒè„šæœ¬é€‚é…å®Œæˆ")
        print("5. âœ… é¢„å¤„ç†è„šæœ¬é€‚é…å®Œæˆ")
        print("6. âœ… æ•°æ®é›†å’Œæ¨¡å‹æ–‡ä»¶é€‚é…å®Œæˆ")
        print("\nç°åœ¨ä½ å¯ä»¥ä½¿ç”¨æ–°çš„é…ç½®ç»“æ„æ¥è¿è¡Œå„ä¸ªè®­ç»ƒè„šæœ¬äº†!")
    else:
        print("\nâŒ é‡æ„è¿‡ç¨‹ä¸­å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ã€‚")
        sys.exit(1)
