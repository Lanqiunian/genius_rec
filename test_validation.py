#!/usr/bin/env python3
"""
ä¸´æ—¶æµ‹è¯•è„šæœ¬ï¼šéªŒè¯æ¨¡å‹éªŒè¯é˜¶æ®µæ˜¯å¦æ­£å¸¸å·¥ä½œ
ç›´æ¥åŸºäºè®­ç»ƒè„šæœ¬çš„é€»è¾‘æ¥æ„å»ºå’Œæµ‹è¯•æ¨¡å‹
"""

import os
import sys
import torch
import logging
import pickle
import numpy as np
from pathlib import Path
from torch.utils.data import DataLoader

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from src.config import get_config
from src.GeniusRec import GENIUSRecModel
from src.dataset import Seq2SeqRecDataset
from src.unified_evaluation import ValidationDataset, evaluate_model_validation_with_ranking

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_validation():
    """æµ‹è¯•éªŒè¯åŠŸèƒ½ - ç›´æ¥å¤åˆ¶è®­ç»ƒè„šæœ¬çš„é€»è¾‘"""
    try:
        # è®¾ç½®è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_path = "checkpoints/genius_rec_best_0.pth"
        if not os.path.exists(model_path):
            logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
            
        logger.info(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        
        # === å®Œå…¨å¤åˆ¶è®­ç»ƒè„šæœ¬çš„æ•°æ®åŠ è½½é€»è¾‘ ===
        config = get_config()
        
        # æ•°æ®åŠ è½½å’ŒIDæ˜ å°„å¤„ç† (æ¥è‡ªtrain_GeniusRec.py line 249-262)
        logger.info("Loading data from processed directory...")
        with open(config['data']['id_maps_file'], 'rb') as f:
            id_maps = pickle.load(f)
        num_special_tokens = id_maps.get('num_special_tokens', 4)
        total_vocab_size = id_maps['num_items'] + num_special_tokens
        config['encoder_model']['item_num'] = total_vocab_size
        config['decoder_model']['num_items'] = total_vocab_size
        num_items = total_vocab_size
        logger.info(f"ğŸ“Š Vocabulary Info: Total vocabulary size: {total_vocab_size}")
        
        # åˆ›å»ºæ•°æ®é›† (æ¥è‡ªtrain_GeniusRec.py line 263-270)
        val_dataset = Seq2SeqRecDataset(config, config['data']['validation_file'])
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)  # å‡å°batch_size
        pad_token_id = config['pad_token_id']
        top_k = config['evaluation']['top_k']
        logger.info(f"ğŸ“Š Dataset Info: Validation samples: {len(val_dataset)}")

        # æ–‡æœ¬åµŒå…¥åŠ è½½ (æ¥è‡ªtrain_GeniusRec.py line 273-289)
        logger.info("Loading pre-computed and filtered text embeddings...")
        text_embedding_file = config['data']['data_dir'] / 'book_gemini_embeddings_filtered_migrated.npy'
        try:
            text_embeddings_dict = np.load(text_embedding_file, allow_pickle=True).item()
        except FileNotFoundError:
            logger.error(f"Filtered embedding file not found at '{text_embedding_file}'!")
            return False

        text_embedding_dim = next(iter(text_embeddings_dict.values())).shape[0]
        text_embedding_matrix = torch.zeros(total_vocab_size, text_embedding_dim, dtype=torch.float)
        
        item_asin_map = id_maps['item_map']
        loaded_count = 0
        for asin, embedding in text_embeddings_dict.items():
            if asin in item_asin_map:
                item_id = item_asin_map[asin]
                text_embedding_matrix[item_id] = torch.tensor(embedding, dtype=torch.float)
                loaded_count += 1
        
        logger.info(f"Successfully loaded and mapped {loaded_count} text embeddings.")

        # æ¨¡å‹åˆå§‹åŒ– (æ¥è‡ªtrain_GeniusRec.py line 291-299)
        config['decoder_model']['text_embedding_dim'] = text_embedding_dim
        model = GENIUSRecModel(config['encoder_model'], config['decoder_model'], config['expert_system']).to(device)
        logger.info("GENIUS-Rec model created with expert configuration.")
        
        enabled_experts = [k for k, v in config['expert_system']['experts'].items() if v]
        logger.info(f"ğŸ§  å¯ç”¨çš„ä¸“å®¶: {enabled_experts}")
        
        # åŠ è½½æ¨¡å‹æƒé‡
        logger.info("ğŸ’¾ åŠ è½½æ¨¡å‹æƒé‡...")
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)  # ä½¿ç”¨strict=False
            logger.info("âœ… ä» 'model_state_dict' åŠ è½½æƒé‡")
        else:
            model.load_state_dict(checkpoint, strict=False)
            logger.info("âœ… ç›´æ¥åŠ è½½æƒé‡")
            
        # åŠ è½½æ–‡æœ¬åµŒå…¥ (æ¥è‡ªtrain_GeniusRec.py line 387)
        model.decoder.load_text_embeddings(text_embedding_matrix.to(device))
        
        # åŠ è½½å›¾åƒåµŒå…¥ (æ¥è‡ªtrain_GeniusRec.py line 393-480)
        if config['expert_system']['experts']['image_expert']:
            image_embeddings_path = "data/book_image_embeddings_migrated.npy"
            
            if os.path.exists(image_embeddings_path):
                logger.info(f"ğŸ¨ Loading visual expert embeddings from: {image_embeddings_path}")
                try:
                    image_embeddings_dict = np.load(image_embeddings_path, allow_pickle=True).item()
                    
                    if isinstance(image_embeddings_dict, dict) and len(image_embeddings_dict) > 0:
                        sample_embedding = next(iter(image_embeddings_dict.values()))
                        image_embedding_dim = sample_embedding.shape[0]
                        logger.info(f"ğŸ“ Image embedding dimension: {image_embedding_dim}")
                        
                        # æ›´æ–°é…ç½®
                        config['expert_system']['image_expert']['image_embedding_dim'] = image_embedding_dim
                        
                        # åˆ›å»ºå›¾åƒåµŒå…¥çŸ©é˜µ
                        image_embedding_matrix = torch.zeros(num_items, image_embedding_dim, dtype=torch.float)
                        loaded_image_count = 0
                        
                        for item_id, embedding in image_embeddings_dict.items():
                            if isinstance(item_id, (int, np.int32, np.int64)) and 0 <= item_id < num_items:
                                image_embedding_matrix[item_id] = torch.tensor(embedding, dtype=torch.float)
                                loaded_image_count += 1
                        
                        model.decoder.load_image_embeddings(image_embedding_matrix.to(device))
                        
                        coverage_rate = (loaded_image_count / num_items) * 100
                        logger.info(f"âœ… Visual Expert Integration Complete!")
                        logger.info(f"   ğŸ“Š Loaded {loaded_image_count:,} image embeddings")
                        logger.info(f"   ğŸ“ˆ Coverage: {coverage_rate:.1f}% of {num_items:,} items")
                        
                except Exception as e:
                    logger.error(f"Failed to load image embeddings: {e}")
                    return False
            else:
                logger.warning(f"âš ï¸ å›¾åƒåµŒå…¥æ–‡ä»¶ä¸å­˜åœ¨: {image_embeddings_path}")
        
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()
        logger.info("ğŸ” æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼")
        
        # æµ‹è¯•éªŒè¯åŠŸèƒ½ - ç›´æ¥å¤åˆ¶è®­ç»ƒè„šæœ¬çš„å…¨é‡è¯„ä¼°é€»è¾‘
        logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•éªŒè¯åŠŸèƒ½...")
        
        # åˆ›å»ºæŸå¤±å‡½æ•° (æ¥è‡ªtrain_GeniusRec.py line 530)
        import torch.nn as nn
        criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id, label_smoothing=config['finetune'].get('label_smoothing', 0))
        
        # ä½¿ç”¨å…¨é‡è¯„ä¼°ï¼Œç›´æ¥å¯¹é½è®­ç»ƒè„šæœ¬ (æ¥è‡ªtrain_GeniusRec.py line 560-567)
        num_candidates = None  # å…¨é‡è¯„ä¼°ï¼Œä¸é™åˆ¶å€™é€‰æ•°é‡
        
        try:
            eval_results = evaluate_model_validation_with_ranking(
                model, val_loader, criterion, device,
                0, 1, pad_token_id,  # epoch=0, num_epochs=1
                config=config, num_candidates=num_candidates, top_k=top_k
            )
            
            logger.info("ğŸ‰ éªŒè¯åŠŸèƒ½æµ‹è¯•æˆåŠŸï¼")
            logger.info("ğŸ“Š éªŒè¯ç»“æœ:")
            for metric, value in eval_results.items():
                if isinstance(value, (int, float)):
                    logger.info(f"   - {metric}: {value:.4f}")
                else:
                    logger.info(f"   - {metric}: {value}")
                
            return True
            
        except Exception as eval_error:
            logger.error(f"âŒ éªŒè¯åŠŸèƒ½æµ‹è¯•å¤±è´¥: {eval_error}")
            import traceback
            traceback.print_exc()
            return False
            
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª å¼€å§‹éªŒè¯åŠŸèƒ½æµ‹è¯•")
    logger.info("=" * 60)
    
    # æ£€æŸ¥GPUå†…å­˜
    if torch.cuda.is_available():
        logger.info(f"ğŸ’¾ GPUæ˜¾å­˜çŠ¶æ€:")
        logger.info(f"   - å·²åˆ†é…: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
        logger.info(f"   - å·²é¢„ç•™: {torch.cuda.memory_reserved()/1024**3:.2f}GB")
        logger.info(f"   - æ€»å®¹é‡: {torch.cuda.get_device_properties(0).total_memory/1024**3:.2f}GB")
        logger.info(f"   - å‰©ä½™å¯ç”¨: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved())/1024**3:.2f}GB")
    
    success = test_validation()
    
    logger.info("=" * 60)
    if success:
        logger.info("âœ… éªŒè¯åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å®‰å…¨è¿›è¡Œå®Œæ•´è®­ç»ƒã€‚")
    else:
        logger.info("âŒ éªŒè¯åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼éœ€è¦ä¿®å¤é—®é¢˜ã€‚")
    logger.info("=" * 60)

if __name__ == "__main__":
    main()
